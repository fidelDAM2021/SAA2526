{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CE IA i Big Data Curs 25/26","text":""},{"location":"#sistemes-daprenentatge-automatic","title":"Sistemes d'Aprenentatge Autom\u00e0tic","text":"<ul> <li>0. Presentaci\u00f3</li> <li>1. Introducci\u00f3 a la Intel\u00b7lig\u00e8ncia Artificial</li> <li>2. Introducci\u00f3 als Sistemes d'Aprenentatge Autom\u00e0tic</li> <li>3. Preprocessament i estad\u00edstica</li> <li>4. Aprenentatge supervisat</li> </ul>"},{"location":"documents/","title":"Presentaci\u00f3 del m\u00f2dul Sistemes d'Aprenentatge Autom\u00e0tic (SAA)","text":"Professor: Fidel Oltra Contacte: jf.oltralandete@edu.gva.es"},{"location":"documents/#descripcio-del-modul-saa","title":"Descripci\u00f3 del m\u00f2dul SAA","text":"<p>El m\u00f2dul de Sistemes d'Aprenentatge Autom\u00e0tic (SAA) forma part del Curs d'Especialitzaci\u00f3 en IA i Big Data (IABD) i t\u00e9 una durada de 90 hores. El m\u00f2dul est\u00e0 dissenyat per proporcionar als estudiants els coneixements i habilitats necessaris per analitzar i relacionar les t\u00e8cniques d'aprenentatge autom\u00e0tic amb la predicci\u00f3 de comportaments futurs que milloren l'efici\u00e8ncia operativa de les organitzacions i empreses.</p>"},{"location":"documents/#temporalitzacio","title":"Temporalitzaci\u00f3","text":"<p>3 hores a la setmana al llarg de 30 setmanes.</p> <p>Dilluns: 18:45 - 21:30 </p>"},{"location":"documents/#objectius","title":"Objectius","text":"<p>Els objectius generals del Curs d'Especialitzaci\u00f3 en IA i Big Data se concreten, en cada m\u00f2dul, en els seus Resultats d'Aprenentatge (RA) i Criteris d'Avaluaci\u00f3 (CA) que se detallen en la programaci\u00f3 del m\u00f2dul.</p> <p>Els Resultats d'Aprenentatge (RA) espec\u00edfics del m\u00f2dul SAA s\u00f3n:</p> <ul> <li> <p>RA1: Caracteritza la intel\u00b7lig\u00e8ncia artificial forta i feble determinant els seus usos i possibilitats.</p> </li> <li> <p>RA2: Determina t\u00e8cniques i eines de sistemes d'aprenentatge autom\u00e0tic (Machine Learning), testejant la seua aplicabilitat en la resoluci\u00f3 de problemes.</p> </li> <li> <p>RA3: Aplica algorismes d'aprenentatge supervisat, optimitzant el resultat del model i minimitzant els riscos associats.</p> </li> <li> <p>RA4: Aplica t\u00e8cniques d'aprenentatge no supervisat relacionant-les amb els tipus de problemes que tracten de resoldre.</p> </li> <li> <p>RA5: Aplica models computacionals de xarxes neuronals comparant-los amb altres m\u00e8todes d'intel\u00b7lig\u00e8ncia artificial.</p> </li> <li> <p>RA6: Valora la qualitat dels resultats obtinguts en la pr\u00e0ctica amb sistemes d'aprenentatge autom\u00e0tic integrant principis fonamentals de la computaci\u00f3.</p> </li> </ul>"},{"location":"documents/#competencies-professionals","title":"Compet\u00e8ncies professionals","text":"<ul> <li> <p>a) Aplicar sistemes d'Intel\u00b7lig\u00e8ncia Artificial per identificar noves formes d'interacci\u00f3 en els negocis que milloren la productivitat.</p> </li> <li> <p>c) Gestionar la transformaci\u00f3 digital necess\u00e0ria a les organitzacions per a la consecuci\u00f3 de l\u2019efici\u00e8ncia empresarial mitjan\u00e7ant el tractament de dades.</p> </li> <li> <p>d) Aplicar Intel\u00b7lig\u00e8ncia Artificial en funcionalitats, processos i sistemes de decisi\u00f3 empresarials.</p> </li> <li> <p>e) Gestionar els diferents tipus d'Intel\u00b7lig\u00e8ncia Artificial per a la consecuci\u00f3 de transformaci\u00f3 i canvi en les empreses.</p> </li> <li> <p>f) Administrar el desenvolupament de processos automatitzats que permeten la millora de la productivitat de les empreses.</p> </li> <li> <p>g) Optimitzar el desenvolupament de processos aut\u00f2noms utilitzant eines d'Intel\u00b7lig\u00e8ncia Artificial.</p> </li> <li> <p>j) Executar el sistema d\u2019explotaci\u00f3 de dades segons les necessitats d\u2019\u00fas i les condicions de seguretat establertes assegurant el compliment dels principis legals i \u00e8tics.</p> </li> <li> <p>k) Configurar les eines que es fan servir per construir solucions Big Data i d\u2019Intel\u00b7lig\u00e8ncia Artificial.</p> </li> </ul>"},{"location":"documents/#continguts","title":"Continguts","text":"<p>Els continguts d\u2019aquest m\u00f2dul professional, segons estableix el curr\u00edculum vigent, s\u00f3n els seg\u00fcents:</p> <ul> <li> <p>C1. Caracteritzaci\u00f3 de l'Intel\u00b7lig\u00e8ncia Artificial forta i feble.</p> </li> <li> <p>C2. Determinaci\u00f3 de Sistemes d'Aprenentatge Autom\u00e0tic.</p> </li> <li> <p>C3. Algorismes aplicables a l'aprenentatge supervisat i optimitzaci\u00f3 del model.</p> </li> <li> <p>C4. Aplicaci\u00f3 de t\u00e8cniques d'aprenentatge no supervisat.</p> </li> <li> <p>C5. Aplicaci\u00f3 de models computacionals de xarxes neuronals i comparatives amb altres models.</p> </li> <li> <p>C6. Valoraci\u00f3 de la qualitat dels resultats obtinguts en la pr\u00e0ctica amb sistemes d'aprenentatge autom\u00e0tic.</p> </li> </ul>"},{"location":"documents/#unitats-de-programacio","title":"Unitats de programaci\u00f3","text":"<p>UP01: Introducci\u00f3 als Sistemes d'Aprenentatge Autom\u00e0tic. UP02: Machine Learning. UP03: Aprenentatge supervisat. UP04: Aprenentatge no supervisat. UP05: Xarxes neuronals. UP06: Avaluaci\u00f3, optimitzaci\u00f3 i implementaci\u00f3 de models.</p>"},{"location":"documents/#metodologia","title":"Metodologia","text":"<ul> <li> <p>Apunts, exemples, pr\u00e0ctiques i documentaci\u00f3 en la plataforma Aules.</p> </li> <li> <p>Aprenentatge basat en Reptes (ABR) i Projectes (ABP), mitjan\u00e7ant el desenvolupament primer de reptes m\u00e9s concrets i, m\u00e9s endavant, de projectes intermodulars reals complets, proposats, sempre que siga possible, en col\u00b7laboraci\u00f3 amb empreses i organitzacions.</p> </li> <li> <p>Aprenentatge col\u00b7laboratiu, en els propis projectes i reptes, que s'abordaran mitjan\u00e7ant el treball en equip i amb eines de gesti\u00f3 de projectes.</p> </li> <li> <p>Classe invertida (Flipped Classroom), on l'alumnat treballa els continguts pel seu compte, i aprofita els problemes que va trobant al llarg del desenvolupament dels projectes i reptes, o en la resoluci\u00f3 d'exercicis, per preguntar a l'aula els seus dubtes. La classe per tant esdev\u00e9 un espai de resoluci\u00f3 de dubtes i d'aplicaci\u00f3 pr\u00e0ctica dels continguts.</p> </li> </ul>"},{"location":"u01/","title":"Introducci\u00f3 a la intel\u00b7lig\u00e8ncia Artificial","text":"<p>En esta primera unitat anem a introduir conceptes b\u00e0sics sobre intel\u00b7lig\u00e8ncia artificial i models d'IA. La introducci\u00f3 ser\u00e0 comuna als m\u00f2duls de Models d'Intel\u00b7lig\u00e8ncia Artificial i Sistemes d'Aprenentatge Autom\u00e0tic, per la qual cosa molts conceptes es repetiran en ambd\u00f3s m\u00f2duls.</p>"},{"location":"u01/#definicio-i-conceptes-basics","title":"Definici\u00f3 i conceptes b\u00e0sics","text":"<p>Una primera definici\u00f3 d'intel\u00b7lig\u00e8ncia artificial (IA) podria ser la seg\u00fcent: habilitat per aprendre i resoldre problemes duta a terme per una m\u00e0quina o programari.</p> <p>Si entenem com IA la capacitat d'una m\u00e0quina per a simular processos d'intel\u00b7lig\u00e8ncia humana, podem establir almenys tres punts clau:</p> <ul> <li>Aprenentatge: La IA ha de ser capa\u00e7 d'aprendre de l'experi\u00e8ncia, tant inicialment a partir d'unes regles / dades inicials, com millorant el seu rendiment a mesura que s'exposa a m\u00e9s dades o situacions (autocorrecci\u00f3).</li> <li>Raonament: La IA ha de ser capa\u00e7 de raonar i prendre decisions basades en la informaci\u00f3 disponible, utilitzant l\u00f2gica i coneixements previs.</li> <li>Resoluci\u00f3 de problemes: La IA ha de ser capa\u00e7 de resoldre problemes complexos i adaptar-se a noves situacions, utilitzant estrat\u00e8gies i t\u00e8cniques adequades.</li> </ul> <p>Una m\u00e0quina intel\u00b7ligent, \u00e9s a dir, capa\u00e7 de realitzar les tasques dites anteriorment, seria un agent flexible que percep el seu entorn i porta a terme accions que maximitzen les seues possibilitats d'\u00e8xit en objectius i tasques concretes.</p> <p>El concepte d'intel\u00b7lig\u00e8ncia artificial (IA) no \u00e9s el mateix ara que fa, per exemple, 50 anys. En unes d\u00e8cades hem passat d'unes m\u00e0quines que eren capaces de realitzar c\u00e0lculs senzills a sistemes que poden aprendre, raonar i prendre decisions complexes. Els objectius tamb\u00e9 han anat canviat al llarg del temps. En un principi eren molt ambiciosos, per\u00f2 no existia la tecnologia necess\u00e0ria. Poc a poc els objectius s'han anat fent m\u00e9s realistes i adaptant-se a la tecnologia existent en cada moment. </p> <p>Aix\u00ed, des dels anys 60 hem passat d'un objectiu inicial que pretenia replicar el proc\u00e9s de la intel\u00b7lig\u00e8ncia humana, a uns altres m\u00e9s pragm\u00e0tics i concrets. Els avan\u00e7os que s'han produ\u00eft tant en el camp de la IA com en el hardware i software necessaris, han fet que tornem a mirar endavant amb m\u00e9s ambici\u00f3. La idea de crear m\u00e0quines que puguen pensar i actuar com humans ha evolucionat cap a la creaci\u00f3 de sistemes que poden aprendre i adaptar-se a noves situacions, processar grans volums de dades i resoldre problemes complexos de manera aut\u00f2noma, per\u00f2 sense perdre de vista la possibilitat d'arribar a que la IA puga raonar, aprendre i actuar con un \u00e9sser hum\u00e0; fins i tot, que puga superar les capacitats humanes en certes tasques.</p> <p>\u00c9s per aix\u00f2 que tenim, com veurem m\u00e9s endavant, diferents enfocaments i tipus d'intel\u00b7lig\u00e8ncia artificial, que van des de la IA feble, que es centra en tasques espec\u00edfiques i limitades, fins a la IA forta, que pret\u00e9n replicar la intel\u00b7lig\u00e8ncia humana en tota la seua complexitat.</p> <p>Fins i tot una eina com chatGPT, que sembla que sap fer de tot, \u00e9s realment una IA feble centrada b\u00e0sicament en una \u00fanica tasca: processament del llenguatge. Tornarem m\u00e9s endavant sobre este concepte.</p>"},{"location":"u01/#historia-i-evolucio-de-la-ia","title":"Hist\u00f2ria i evoluci\u00f3 de la IA","text":"<p>Encara que semble que la intel\u00b7lig\u00e8ncia artificial \u00e9s un concepte recent, les seues arrels es remunten a fa m\u00e9s de 70 anys. En esta unitat farem un rep\u00e0s breu de la hist\u00f2ria i l'evoluci\u00f3 de la IA, des dels seus inicis fins als avan\u00e7os m\u00e9s recents.</p> <ul> <li>1943: Warren McCulloch i Walter Pitts publiquen un article que proposa un model matem\u00e0tic per a les neurones, establint les bases de les xarxes neuronals. </li> <li>1950: Alan Turing proposa el Test de Turing, un criteri per a determinar si una m\u00e0quina pot exhibir un comportament intel\u00b7ligent indistinguible del d'un \u00e9sser hum\u00e0.</li> <li>1956: En la Confer\u00e8ncia de Dartmouth, John McCarthy, Marvin Minsky i altres investigadors defineixen el terme \"intel\u00b7lig\u00e8ncia artificial\" i estableixen les bases per a la investigaci\u00f3 en este camp.</li> <li>1958: Se desenvolupa el llenguatge de programaci\u00f3 LISP, que es converteix en un dels llenguatges m\u00e9s utilitzats en la investigaci\u00f3 d'IA. Tamb\u00e9 apareix el perceptr\u00f3n, un algorisme de xarxa neuronal proposat per Frank Rosenblatt per a reconeixement de patrons. Concretament, s'utilitzava per a recon\u00e8ixer formes simples i classificar imatges.</li> <li>1959: Desenvolupament dels primers sistemes d'IA que utilitzaven regles per a resoldre problemes matem\u00e0tics i demostrar certs teoremes.</li> <li>1960s: Se desenvolupen els primers sistemes d'IA especialitzats, com ELIZA, un programa de processament del llenguatge natural que simulava una conversa amb un terapeuta, ordinadors que juguen als escacs, sistemes que resolen problemes matem\u00e0tics... Sempre tasques molt espec\u00edfiques i limitades.</li> <li>1966-1970: els resultats estan per baix de les expectatives i es produeix un primer per\u00edode de desencantament amb la IA, conegut com \"l'hivern de la IA\". Els investigadors es donen compte que les expectatives inicials eren massa altes i que els avan\u00e7os s\u00f3n m\u00e9s lents del que s'esperava. Se reajusten els objectius.</li> <li>1970s: S'investiga en sistemes basats en el coneixement, com els sistemes experts, que utilitzaven regles i coneixements espec\u00edfics per a resoldre problemes en \u00e0rees com la medicina o l'enginyeria. </li> <li>1980s: S'inicia un segon per\u00edode d'inter\u00e8s per la IA, impulsat per l'augment de la pot\u00e8ncia de c\u00e0lcul i el desenvolupament de noves t\u00e8cniques d'aprenentatge autom\u00e0tic. Se torna a investigar en xarxes neuronals hi ha avan\u00e7os, per\u00f2 els models s\u00f3n molt complexos i necessiten supervisi\u00f3 constant i ajustos manuals. Segon hivern de la IA.</li> <li>1990s i 2000s: IA moderna, basada en probabilitat i estad\u00edstica, que permet arribar a conclusions futures a partir de dades passades. Models basats en dades, m\u00e9s flexibles que els models simb\u00f2lics.</li> <li>1997: Hui sembla una an\u00e8cdota, per\u00f2 l'ordinador Deep Blue d'IBM guanya al campi\u00f3 mundial d'escacs Garry Kasparov, marcant un moment hist\u00f2ric en la IA.</li> <li>2010s: la gran quantitat de dades i les t\u00e8cniques de tractament (Big Data), aix\u00ed com la computaci\u00f3 al n\u00favol (menys necessitat de recursos locals), permeten l'\u00fas de models d'aprenentatge profund (Deep Learning) i xarxes neuronals convolucionals, que han revolucionat la IA en \u00e0rees com la visi\u00f3 per computador i el processament del llenguatge natural.</li> <li>Algunes fites dels darrers anys:</li> <li>2011: IBM Watson guanya el concurs de preguntes i respostes Jeopardy!, demostrant la capacitat de processar i entendre el llenguatge natural.</li> <li>2012: AlexNet guanya la competici\u00f3 ImageNet, demostrant l'efic\u00e0cia de les xarxes neuronals profundes en el reconeixement d'imatges.</li> <li>el v\u00eddeo dels 500 milions de d\u00f2lars de DeepMind: Deep-Q aprenent a jugar el joc Atari Breakout. enlla\u00e7 per veure el video</li> <li>2015: Google allibera el seu sistema d'IA, TensorFlow, que es converteix en un dels marcs m\u00e9s utilitzats per a l'aprenentatge autom\u00e0tic i les xarxes neuronals.</li> <li>2016: AlphaGo, desenvolupat per DeepMind, guanya al campi\u00f3 mundial de Go, un joc extremadament complex.</li> <li>2020: GPT-3, un model de llenguatge natural desenvolupat per OpenAI, demostra una capacitat sorprenent per a generar text coherent i realista que ha anat millorant molt des d'aleshores. Utilitza 175 mil milions de par\u00e0metres i \u00e9s capa\u00e7 de realitzar una \u00e0mplia gamma de tasques de processament del llenguatge natural, com traducci\u00f3, resum, generaci\u00f3 de text i resposta a preguntes. OpenAI no ha donat informaci\u00f3 de quants par\u00e0metres t\u00e9 el model GPT-4, tot i que certes fonts parlen de 250 mil millions. GPT-5 podria tindre m\u00e9s d'un bili\u00f3 de par\u00e0metres.</li> <li>2021: DALL-E, un model generatiu d'imatges desenvolupat per OpenAI, que pot generar imatges a partir de descripcions textuals.</li> <li>2022-2025: Agents intel\u00b7ligents com DeepSeek, Gemini (Google), NotebookLM (Google), Claude (Anthropic)... que combinen models de llenguatge amb altres capacitats, com la visi\u00f3 per computador, la raonament l\u00f2gic i la planificaci\u00f3. </li> <li>Capacitat de generar imatges, v\u00eddeos i \u00e0udio de manera realista, com DALL-E, Stable Diffusion, Midjourney... Imatges de rostres humans inexistents.</li> <li>Deep Learning*: una branca de l'aprenentatge autom\u00e0tic del que analitzarem m\u00e9s detalladament en el m\u00f2dul de Sistemes d'Aprenentatge Autom\u00e0tic**, on estudiarem tamb\u00e9 els diferents tipus d'aprenentatge autom\u00e0tic (supervisat, no supervisat, per refor\u00e7).</li> </ul>"},{"location":"u01/#tipus-dintelligencia-artificial","title":"Tipus d'intel\u00b7lig\u00e8ncia artificial","text":"<p>La intel\u00b7lig\u00e8ncia artificial es pot classificar en diferents tipus segons el seu enfocament i les seues capacitats. En este apartat, veurem els principals tipus d'IA, des de la IA feble fins a la IA forta, i les seues caracter\u00edstiques distintives.</p>"},{"location":"u01/#ia-feble","title":"IA feble","text":"<p>La IA feble, tamb\u00e9 coneguda com a IA estreta (narrow AI), es refereix a sistemes d'intel\u00b7lig\u00e8ncia artificial dissenyats per a realitzar tasques espec\u00edfiques i limitades. Estos sistemes no tenen consci\u00e8ncia ni comprensi\u00f3 general del m\u00f3n, sin\u00f3 que estan enfocats en resoldre problemes concrets. S\u00f3n reactius, la qual cosa vol dir que no tenen iniciativa sino que reaccionen a certes ordres o accions. No \"aprenen\" com un \u00e9sser hum\u00e0: \"entrenen\" amb dades o per amb moltes proves/errors.</p> <p>Alguns exemples d'IA feble inclouen:</p> <ul> <li>Assistents virtuals com Siri o Alexa, que poden respondre preguntes i realitzar tasques senzilles.</li> <li>Algoritmes de recomanaci\u00f3 en plataformes com Netflix o Amazon, que suggereixen contingut basat en les prefer\u00e8ncies de l'usuari.</li> <li>Sistemes de reconeixement de veu i imatge, que poden identificar patrons en dades espec\u00edfiques.   </li> </ul> <p>Com podeu veure, la IA feble \u00e9s la que s'ha estat desenvolupant i utilitzant en els darrers anys, i \u00e9s la que trobem en la majoria de les aplicacions d'IA actuals. La seua limitaci\u00f3 \u00e9s que no pot generalitzar coneixements ni aprendre de manera aut\u00f2noma fora del seu \u00e0mbit espec\u00edfic. Per tal de poder superar els \"hiverns de la IA\", se va apostar per este enfocament m\u00e9s pragm\u00e0tic i realista.</p>"},{"location":"u01/#ia-forta","title":"IA forta","text":"<p>La IA forta, tamb\u00e9 coneguda com a IA general (general AI), es refereix a sistemes d'intel\u00b7lig\u00e8ncia artificial que tenen la capacitat de comprendre, aprendre i aplicar coneixements en una \u00e0mplia gamma de tasques, similar a la intel\u00b7lig\u00e8ncia humana. Estos sistemes podrien raonar, planificar, resoldre problemes i adaptar-se a noves situacions sense necessitat d'intervenci\u00f3 humana constant. En teoria serien proactives, \u00e9s a dir, no necessitarian una ordre o un \u00e9sser hum\u00e0 demanant-li una tasca. Tamb\u00e9 en teoria (de moment), serien capaces de raonar com un \u00e9sser hum\u00e0.</p> <p>La IA forta encara \u00e9s un objectiu a llarg termini en la investigaci\u00f3 d'IA, i no s'ha aconseguit completament. No obstant aix\u00f2, els avan\u00e7os en \u00e0rees com l'aprenentatge autom\u00e0tic, les xarxes neuronals i el processament del llenguatge natural estan apropant-nos cada vegada m\u00e9s a este objectiu.</p> <p></p>"},{"location":"u01/#debats","title":"Debats:","text":"<ul> <li>IA feble vs IA forta</li> <li>chatGPT, DeepSeek, NotebookLM, Gemini... S\u00f3n IAs febles o fortes?</li> </ul>"},{"location":"u01/#ia-simbolica-convencional-vs-ia-basada-en-dades-computacional","title":"IA simb\u00f2lica (convencional) vs IA basada en dades (computacional)","text":"<p>La IA simb\u00f2lica (o convencional) es basa en la representaci\u00f3 del coneixement mitjan\u00e7ant s\u00edmbols i regles l\u00f2giques. Este enfocament utilitza sistemes basats en regles, l\u00f2gica i raonament per a resoldre problemes i prendre decisions. La IA simb\u00f2lica ha estat utilitzada en sistemes experts i en la resoluci\u00f3 de problemes matem\u00e0tics. \u00c9s poc flexible i complicada d'escalar. En els anys 80 utilitz\u00e0vem llenguatges com Prolog o Lisp per a programar este tipus d'IA. La IA simb\u00f2lica (de vegades anomenada IA cl\u00e0ssica), per tant, requereix un coneixement previ i expl\u00edcit per a funcionar, i es basa en la l\u00f2gica i les regles per a processar la informaci\u00f3.</p> <p>Exemples d'IA simb\u00f2lica inclouen:</p> <ul> <li>Sistemes experts que utilitzen regles per a resoldre problemes en \u00e0rees espec\u00edfiques, com la medicina o l'enginyeria.</li> <li>Xarxes bayesianes (grafos) que utilitzen probabilitats per a inferir conclusions a partir de dades (plou --&gt; la terra est\u00e0 mullada).</li> <li>Sistemes de raonament l\u00f2gic que poden deduir conclusions a partir de premisses i regles.</li> <li>Sistemes de processament del llenguatge natural que utilitzen gram\u00e0tiques i regles per a analitzar i generar text.</li> </ul> <p>Esta seria la part que veuriem en este m\u00f2dul de Models d'Intelig\u00e8ncia Artificial. </p> <p>La IA basada en dades (o computacional), en canvi, es fonamenta en l'aprenentatge autom\u00e0tic i l'an\u00e0lisi de grans volums de dades per a identificar patrons i fer prediccions. No treballa amb regles sino amb exemples i generalitzacions. Este enfocament ha guanyat popularitat en els darrers anys gr\u00e0cies a l'augment de la pot\u00e8ncia de c\u00e0lcul i la disponibilitat de dades massives. Ac\u00ed entraria tant el Machine Learning com el Deep Learning (ja veurem les difer\u00e8ncies).</p> <p>Exemples d'IA basada en dades inclouen:</p> <ul> <li>Algoritmes de classificaci\u00f3 i regressi\u00f3 que utilitzen dades hist\u00f2riques per a fer prediccions sobre esdeveniments futurs.</li> <li>Xarxes neuronals que aprenen a recon\u00e8ixer patrons en imatges, veu o text.</li> <li>Models de processament del llenguatge natural que utilitzen t\u00e8cniques d'aprenentatge autom\u00e0tic per a analitzar i generar text de manera coherent. Per exemple, per mantindre una conversa o per fer an\u00e0lisi de sentiments (determinar si un text expressa una opini\u00f3 positiva, negativa o neutra).</li> <li>Sistemes de recomanaci\u00f3 que utilitzen dades d'usuari per a suggerir contingut personalitzat, com pel\u00b7l\u00edcules, m\u00fasica o productes.</li> </ul> <p>La part de la IA basada en dades i en l'aprenentatge autom\u00e0tic \u00e9s la que veurem en este m\u00f2dul. La IA simb\u00f2lica (algorismes, processament del llenguatge natural, rob\u00f2tica, sistemes experts, etc.) se veur\u00e0 al m\u00f2dul de Models d'Intel\u00b7lig\u00e8ncia Artificial.</p> <p>Podr\u00edem dir que la IA simb\u00f2lica se programa a la manera (m\u00e9s o menys) tradicional, mentre que la IA basada en dades s'entrena a partir de dades. Aix\u00f2 implica que la IA simb\u00f2lica requereix un coneixement previ i expl\u00edcit per a funcionar, mentre que la IA basada en dades pot aprendre de manera aut\u00f2noma a partir de les dades que se li proporcionen.</p> <p>Tamb\u00e9 se parla d'una IA h\u00edbrida, que combina xarxes neuronals (de la IA computacional) amb regles i representacions simb\u00f2liques (de la IA simb\u00f2lica o convencional). En eixa classificaci\u00f3 podrien entrar eines com chatGPT.</p> <p></p>"},{"location":"u01/#ia-generativa","title":"IA Generativa","text":"<p>La IA generativa \u00e9s un tipus d'intel\u00b7lig\u00e8ncia artificial que es centra en la creaci\u00f3 de contingut nou i original, com imatges, m\u00fasica, text o fins i tot v\u00eddeos. A difer\u00e8ncia d'altres tipus d'IA que es basen en l'an\u00e0lisi i la classificaci\u00f3 de dades existents, la IA generativa utilitza models avan\u00e7ats per a generar contingut que no existia pr\u00e8viament.</p> <p>Podr\u00edem classificar la IA generativa dins de la IA basada en dades, ja que utilitza grans quantitats de dades per a entrenar els seus models. No obstant aix\u00f2, la seua capacitat per a crear contingut nou i original la fa destacar com un tipus d'IA amb caracter\u00edstiques pr\u00f2pies.</p>"},{"location":"u01/#camps-daplicacio-de-la-ia","title":"Camps d'aplicaci\u00f3 de la IA","text":"<p>La intel\u00b7lig\u00e8ncia artificial t\u00e9 una \u00e0mplia gamma d'aplicacions en diversos camps. Algunes de les \u00e0rees m\u00e9s destacades on s'est\u00e0 utilitzant la IA s\u00f3n:</p> <ul> <li>Processament del llenguatge natural (NLP): La IA s'utilitza per a analitzar, comprendre i generar text en llenguatge hum\u00e0. Aix\u00f2 inclou traducci\u00f3 autom\u00e0tica, assistents virtuals, an\u00e0lisi de sentiments i generaci\u00f3 de text.</li> <li>Visi\u00f3 per computador: La IA s'aplica en el reconeixement d'imatges i v\u00eddeos, permetent la detecci\u00f3 d'objectes, el reconeixement facial i la classificaci\u00f3 d'imatges. Aix\u00f2 \u00e9s \u00fatil en \u00e0rees com la seguretat, la salut i l'automoci\u00f3.</li> <li>Rob\u00f2tica: La IA s'utilitza per a controlar robots i sistemes aut\u00f2noms, permetent-los realitzar tasques complexes com la navegaci\u00f3, la manipulaci\u00f3 d'objectes i la interacci\u00f3 amb humans. Aix\u00f2 inclou robots de neteja, drones i vehicles aut\u00f2noms.</li> <li>Sistemes de recomanaci\u00f3: La IA s'aplica en plataformes com Netflix, Amazon i Spotify per a suggerir contingut personalitzat als usuaris, basant-se en les seues prefer\u00e8ncies i comportaments anteriors.</li> <li>Models predictius: La IA s'utilitza per a analitzar dades hist\u00f2riques i fer prediccions sobre esdeveniments futurs. Aix\u00f2 \u00e9s \u00fatil en \u00e0rees com la salut, les finances, el clima i la log\u00edstica, entre altres.</li> <li>Models generatius: La IA s'aplica en la creaci\u00f3 de contingut nou, com imatges, m\u00fasica i text. Aix\u00f2 inclou models com DALL-E, que generen imatges a partir de descripcions textuals, i GPT-3, que pot generar text coherent i realista (aix\u00f2 formaria part del camp del processament del llenguatge natural).</li> <li>Agents intel\u00b7ligents: La IA s'utilitza per a crear agents aut\u00f2noms que poden interactuar amb el seu entorn, prendre decisions i aprendre de l'experi\u00e8ncia. Aix\u00f2 inclou sistemes de navegaci\u00f3, assistents virtuals i robots aut\u00f2noms. Ara parlarem d'ells.</li> </ul>"},{"location":"u01/#agents-intelligents","title":"Agents intel\u00b7ligents","text":"<p>Els agents intel\u00b7ligents s\u00f3n entitats capaces de percebre el seu entorn a trav\u00e9s de sensors i actuar-hi mitjan\u00e7ant efectors per assolir objectius espec\u00edfics. Se caracteritzen per tindre:</p> <ul> <li>autonomia</li> <li>reactivitat</li> <li>proactivitat (iniciativa)</li> <li>capacitat d'interactuar</li> <li>mem\u00f2ria i planificaci\u00f3 (context intern i extern)</li> </ul> <p>Components d'un agent intel\u00b7ligent:</p> <ul> <li>Sensors(S): Els sensors s\u00f3n dispositius que permeten a l'agent percebre informaci\u00f3 sobre el seu entorn. Poden incloure c\u00e0meres, micr\u00f2fons, sensors de temperatura, GPS, entre d'altres. La informaci\u00f3 que recopilen els sensors s'utilitza per representar l'estat actual de l'entorn.</li> <li>Actuadors(A): Els actuadors s\u00f3n els mitjans mitjan\u00e7ant els quals l'agent interactua amb el seu entorn. Poden ser rodes en un robot, motors en un bra\u00e7 rob\u00f2tic o simplement sortides de dades en un sistema de programari. Els actuadors permeten que l'agent faci accions per assolir els objectius.</li> <li>Funci\u00f3 (F): La funci\u00f3 de l'agent representa el comportament de l'agent segons les percepcions que rep. Pren com a entrada l'estat actual de l'entorn i torna una acci\u00f3 que l'agent ha d'executar. Aquesta funci\u00f3 pot ser simple o complexa, depenent de la complexitat de la tasca que lagent ha de realitzar.</li> <li>Arquitectura (A): L'arquitectura de l'agent fa refer\u00e8ncia a com s'organitza l'agent en termes dels seus components i com interactuen entre si. Hi pot haver diferents arquitectures segons la complexitat de la tasca i els requisits de rendiment.</li> </ul> <p>Exemples comuns podrien ser:</p> <ul> <li>un sistema de navegaci\u00f3 o conducci\u00f3 autom\u00e0tica</li> <li>un robot de neteja autom\u00e0tic</li> <li>un assistent virtual com Siri o Alexa</li> <li>un sistema de recomanaci\u00f3 de contingut en l\u00ednia</li> </ul>"},{"location":"u01/#protocols-acp-i-mcp","title":"Protocols ACP i MCP","text":"<p>Els protocols de comunicaci\u00f3 entre agents (ACP, Agent Communication Protocols) s\u00f3n conjunts de regles i convencions que permeten als agents intel\u00b7ligents intercanviar informaci\u00f3 i coordinar les seues accions en un entorn compartit. Aquests protocols s\u00f3n essencials per a la col\u00b7laboraci\u00f3 i la cooperaci\u00f3 entre agents en sistemes multi-agent.</p> <p>D'altra banda, els protocols (MCP, Model Context Protocols) s\u00f3n dissenyats per gestionar i compartir informaci\u00f3 sobre el context en qu\u00e8 operen els agents. Aquests protocols permeten als agents accedir a recursos externs, i per tant adaptar el seu comportament segons les condicions canviants de l'entorn i les necessitats dels altres agents.</p>"},{"location":"u01/#implicacions-etiques-i-socials","title":"Implicacions \u00e8tiques i socials","text":"<ul> <li>Protecci\u00f3 de dades i privacitat: Com es gestionen les dades personals i sensibles en els sistemes d'IA?</li> <li>Informaci\u00f3 molt personal i consentiment: Com es garanteix que els usuaris donen el seu consentiment informat per a l'\u00fas de les seues dades?</li> <li>Discriminaci\u00f3 i biaixos: Com es poden evitar els biaixos en els models d'IA que poden portar a la discriminaci\u00f3 de certs grups?</li> <li>Seguretat i responsabilitat: Qui \u00e9s responsable en cas d'errors o danys causats per sistemes d'IA?</li> <li>Autonomia i control: Com es pot garantir que els sistemes d'IA no prenguin decisions que afecten la vida de les persones sense supervisi\u00f3 humana?</li> <li>Impacte en la societat: Com afectar\u00e0 la IA a les relacions socials, la cultura i la pol\u00edtica?</li> <li>Transpar\u00e8ncia i explicabilitat: Com es poden explicar les decisions preses per sistemes d'IA?</li> <li>Impacte en l'ocupaci\u00f3: Com afectar\u00e0 la IA al mercat laboral i a les professions tradicionals?</li> </ul>"},{"location":"u02/","title":"Sistemes d'Aprenentatge Autom\u00e0tic","text":"<p>En este m\u00f2dul anem a treballar amb una part important de la IA: els Sistemes d'Aprenentatge Autom\u00e1tic (SAA). En primer lloc, i a partir del que hem vist en la introducci\u00f3, caldr\u00e0 definir qu\u00e8 \u00e9s un SAA.</p>"},{"location":"u02/#que-es-laprenentage-automatic","title":"Qu\u00e8 \u00e9s l'Aprenentage autom\u00e0tic.","text":"<p>L'aprenentatge autom\u00e0tic (AA o tamb\u00e9 ML de Machine Learning) \u00e9s un subcamp de la intel\u00b7lig\u00e8ncia artificial que permet als sistemes aprendre i millorar a partir de l'experi\u00e8ncia sense ser expl\u00edcitament programats. Utilitza algoritmes i models matem\u00e0tics per analitzar dades, identificar patrons i fer prediccions o decisions basades en aquesta informaci\u00f3.</p> <p>Encara que intentarem no anar al fons de les matem\u00e0tiques i l'estad\u00edstica que hi ha darrere dels SAA, \u00e9s important tindre en compte que s\u00f3n la seua base. Potser caldr\u00e0 fer un xicotet rep\u00e0s de conceptes en algun moment i explicar-ne d'altres nous amb un nivel de detall comprensible per a tothom.</p> <p>Algunes definicions:</p> <ul> <li> <p>Arthur Samuel (que va treballar per a IBM) el 1959 descrivia l'Aprenentatge Autom\u00e0tic com el camp de l'estudi que d\u00f3na als ordinadors la capacitat d'aprendre sense ser programats expl\u00edcitament.</p> </li> <li> <p>Tom Mitchell (professor a la Universitat de Carnegie Mellon) ha ofert una definici\u00f3 m\u00e9s moderna: Es diu que un programa d'ordinador apr\u00e8n de l'experi\u00e8ncia E pel que fa a alguna classe de tasques T i mesura de rendiment P, si el seu exercici en les tasques en T mesurat per P millora amb l'experi\u00e8ncia E</p> </li> </ul> <p>Per tant, una caracter\u00edstica d'un SAA \u00e9s la capacitat d'aprendre de la seua pr\u00f2pia experi\u00e8ncia. </p> <p></p> <p>Exemple d'escacs (sabeu jugar?):</p> <ul> <li>Primers programes d'escacs: els don\u00e0ven les regles del joc, l'objectiu final, el valor de les peces, les jugades permeses i no permeses, un algorisme per valorar una posici\u00f3... A base de for\u00e7a bruta, trob\u00e0ven les millors jugades.</li> <li>Programes d'escacs actuals: els han donat les regles b\u00e0siques i han apr\u00e9s, en general, jugant moltes partides contra ells mateix o altres models, aprenent de cada partida i millorant.</li> </ul> <p>Tamb\u00e9 podem recordar el programa de Deep Mind que jugava a videojocs de l'Atari 2600 i anava aprenent segons jugava partides i m\u00e9s partides. El sistema estava basat en una Xarxa Neuronal Profunda (Deep Neural Network) que es combinava amb una t\u00e8cnica de Q-learning, una forma d'aprenentatge per refor\u00e7. A mesura que jugava, el sistema rebia recompenses o penalitzacions en funci\u00f3 de les seues accions, i utilitzava esta informaci\u00f3 per ajustar els seus par\u00e0metres i millorar en cada nova partida. Aix\u00ed, aprenia a jugar millor sense cap altra orientaci\u00f3 humana m\u00e9s que el sistema de recompenses. </p>"},{"location":"u02/#exemple-concret-deteccio-de-correu-brossa","title":"Exemple concret: detecci\u00f3 de correu brossa","text":"<p>Imagina que volem crear un filtre capa\u00e7 d'identificar i bloquejar correu brossa (spam). Anem a veure com ho far\u00edem des de la perspectiva cl\u00e0sica, en un sistema basat en regles o heur\u00edstiques, i la difer\u00e8ncia respecte a un sistema basat en Machine Learning:</p> <p>Perspectiva cl\u00e0ssica</p> <p>Els sistemes cl\u00e0ssics de classificaci\u00f3 s'han basat en sistemes de regles o heur\u00edstiques, consistents en la combinaci\u00f3 de condicions per determinar un resultat. Segons aquesta perspectiva, el desenvolupament del filtre implicar\u00eda:</p> <ul> <li>La necessitat d'un analista per fer l'an\u00e0lisi del problema i establir un conjunt de regles. Per exemple si apareix o no el nom del destinatari, si cont\u00e9 faltes ortogr\u00e0fiques, etiquetes html, etc. </li> <li>Avaluaci\u00f3 del sistema de regles. Si \u00e9s v\u00e0lid es passaria a producci\u00f3. Si no ho \u00e9s, l'analista hauria de tornar a analitzar el problema, detectar les mancances i modificar el conjunt de regles.</li> </ul> <p>Com veiem, es tracta d'un proc\u00e9s que dep\u00e9n fortament de la intervenci\u00f3 humana, i que a m\u00e9s requereix d'una actualitzaci\u00f3 constant del conjunt de regles.</p> <p>Perspectiva del Machine Learning</p> <p>Segons aquesta perspectiva, com hem dit, el sistema hauria d'aprendre per ell mateix. Ho ha de fer a partir de les dades i resultats proporcionats. Per a aix\u00f2:</p> <ul> <li>L'analista selecciona una s\u00e8rie de correus, identificant les dades rellevants (caracter\u00edstiques) per a determinar si \u00e9s spam o no.</li> <li>Les dades se netegen, se validen i se transformen per a preparar-les per a l'entrenament.</li> <li>Se selecciona l'algorisme de ML que millor puga contribuir a resoldre el problema.</li> <li>Se proporcionen les dades a l'algorisme (entrenament), i aquest va ajustant una s\u00e8rie de par\u00e0metres en base a tota eixa informaci\u00f3, la qual cosa li permet crear una s\u00e8rie de regles per determinar quan un correu \u00e9s spam o no. La difer\u00e8ncia principal \u00e9s que les regles les va creant el propi sistema, no l'analista.</li> <li>S'avalua el model proporcionant noves dades no utilitzades en l'entrenament i valorant els resultats proporcionants pel model. Si s\u00f3n satisfactoris, es passa a producci\u00f3. Si no ho s\u00f3n, l'analista ha de tornar a analitzar el problema i veure si les dades proporcionades s\u00f3n les adequades o si cal canviar l'algorisme d'entrenament.</li> </ul> <p>Fixeu-vos que si cal canviar alguna cosa en aquest \u00faltim cas, no serien les regles perqu\u00e8 de fet no sabem quines s\u00f3n. Si l'algorisme classifica de forma incorrecta una quantitat excesiva de correus, el problema ha d'estar b\u00e9 en la selecci\u00f3 de les dades per l'entrenament, o en l'algorisme escollit per al model. Eixos serien els aspectes principals per construir un bon sistema de Machine Learning, i per tant els punts que caldria revisar.</p> <p>Per resumir el que hem parlat en una taula:</p> Tipus d'IA Tamb\u00e9 anomenada Com funciona Exemple d\u2019aplicaci\u00f3 en escacs IA simb\u00f2lica / tradicional Programada manualment L\u00f2gica, regles i heur\u00edstiques definides per humans Deep Blue (IBM, 1997) IA conexionista / actual Entrenada amb dades Aprenentatge a partir d\u2019exemples, autoentrenament AlphaZero (DeepMind, 2017) <p>Acabem d'introduir alguns conceptes nous. No us preocupeu, anirem veient-los al llarg del m\u00f2dul.</p> <p>Pr\u00e0cticament tota la IA que coneguem en la actualitat est\u00e0 basada en SAA, o en una combinaci\u00f3 de la IA tradicional (programada) i la SAA (entrenada).</p> <p>Podr\u00edem dir que la IA tradicional \u00e9s com un expert que ho sap tot perqu\u00e8 l'hi ho han explicat, mentre que la IA actual (Aprenentatge Autom\u00e0tic) \u00e9s com un autodidacta que apr\u00e9n jugant i experimentant.</p> <p>Ara, una vegada tenim clar que els sistemes \"aprenen\", hem de diferenciar entre dos tipus d'aprenentatge.</p>"},{"location":"u02/#aprenentatge-supervisat","title":"Aprenentatge supervisat","text":"<p>La caracter\u00edstica fonamental de l'aprenentatge autom\u00e0tic supervisat \u00e9s que aquest aprenentatge es realitza a partir de dades que ja han estat etiquetades pr\u00e8viament. L'algorisme apr\u00e9n a partir d\u2019exemples etiquetats, on cada dada ja t\u00e9 la resposta correcta (la \"etiqueta\") i el model intenta encertar-la.</p> <p>\u00c9s l'exemple cl\u00e0ssic d'entrenament. Per exemple, donar-li moltes fotos de gats i gossos, especificant quines s\u00f3n de gats i quines de gossos, i que el sistema aprenga a diferenciar-los, i despr\u00e9s que intente endevinar, d'una quantitat de fotos no etiquetades, quines s\u00f3n gats i quines s\u00f3n gossos. Un altre exemple podr\u00eda ser classificar correu en spam o normal.</p> <p>Els problemes d'aprenentatge supervisat es divideixen en dues categories: Regressi\u00f3 i Classificaci\u00f3.</p> <p>Regressi\u00f3: Es tracta de predir un valor continu. Per exemple, preveure el preu d'una casa en funci\u00f3 de les seues caracter\u00edstiques (mida, ubicaci\u00f3, nombre de dormitoris, etc.).</p> <p>En general s'utilitzen algorismes de regressi\u00f3 lineal per estimar valors reals de variables amb distribuci\u00f3 cont\u00ednua. Busca generar una l\u00ednia que s'ajuste el millor possible a la distribuci\u00f3 de resultats, minimitzant la dist\u00e0ncia entre els punts i la l\u00ednia. Encara que \u00e9s una t\u00e8cnica estad\u00edstica, \u00e9s un bon punt de partida per entendre els algoritmes de ML.</p> <p>La regressi\u00f3 log\u00edstica, encara que porte la paraula \"regressi\u00f3\", \u00e9s un cas especial que s'utilitza m\u00e9s per a problemes de classificaci\u00f3 bin\u00e0ria, on es vol predir la probabilitat que una inst\u00e0ncia corresponga a una classe espec\u00edfica, pres\u00e8ncia o abs\u00e8ncia d'una caracer\u00edstica, etc.</p> <p>Classificaci\u00f3: Es tracta de predir una classe o categoria discreta. Per exemple, classificar correus electr\u00f2nics com a \"spam\" o \"no spam\", si una foto correspon a una o altra categoria, si una radiografia \u00e9s normal o presenta una patologia, etc.</p> <p>Entre els algorismes de classificaci\u00f3 m\u00e9s comuns estan:</p> <ul> <li>Regresi\u00f3 Log\u00edstica: com hem comentat abans, \u00e9s un algorisme de classificaci\u00f3 que estima valors discrets (ex., SI/NO) predint la probabilitat d'un esdeveniment o la pres\u00e8ncia/abs\u00e8ncia d'una caracter\u00edstica determinada. La funci\u00f3 log\u00edstica es representa amb una corba en forma de S (funci\u00f3 sigmoide).</li> <li>Arbres de decisi\u00f3: Construeixen un model de decisions basat en els atributs de les dades, creant bifurcacions fins a arribar a una decisi\u00f3. S\u00f3n r\u00e0pids, precisos i funcionen b\u00e9 amb dades num\u00e8riques i categ\u00f2riques. L'algorisme CART \u00e9s el m\u00e9s popular.</li> <li>Random Forest: \u00c9s un ensemble d'arbres de decisi\u00f3 que millora la precisi\u00f3 i redueix l'overfitting mitjan\u00e7ant la combinaci\u00f3 de m\u00faltiples arbres. Cada arbre es construeix a partir d'un subconjunt aleatori de les dades i les caracter\u00edstiques, i la predicci\u00f3 final es fa mitjan\u00e7ant la votaci\u00f3 dels arbres.</li> <li>M\u00e0quines de Vectors de Suport (SVM): S'apliquen a problemes de classificaci\u00f3, representant cada inst\u00e0ncia com un punt en un espai n-dimensional i buscant un hiperpl\u00e0 que separe les classes amb el marge m\u00e9s ampli possible. S\u00f3n de les t\u00e8cniques m\u00e9s precises en classificaci\u00f3 i regressi\u00f3. L'\u00fas de les m\u00e0quines de vectors de suport com a classificador s'ha vist incrementat en els \u00faltims anys degut a que serveixen per resoldre problemes de classificaci\u00f3 i regressi\u00f3 amb alt rendiment i precissi\u00f3. S\u00f3n especialment \u00fatils en problemes de classificaci\u00f3 no lineal, on les dades no es poden separar amb una l\u00ednia recta.</li> <li>K-Nearest Neighbors (KNN): Un m\u00e8tode supervisat simple i efectiu per a classificaci\u00f3. Classifica un nou cas basant-se en la majoria de les classes dels seus \"k\" ve\u00efns m\u00e9s propers en un mapa de coordenades. \u00c9s un m\u00e8tode no param\u00e8tric i no \"apr\u00e8n\" en el sentit tradicional, sin\u00f3 que utilitza tot el conjunt de dades com a base de coneixement. L'elecci\u00f3 del valor de K \u00e9s crucial.</li> </ul> <p>L'objectiu \u00e9s que el sistema trobe relacions:</p> <ul> <li>Similituds</li> <li>Difer\u00e8ncies</li> <li>Tend\u00e8ncies</li> </ul>"},{"location":"u02/#aprenentatge-no-supervisat","title":"Aprenentatge no supervisat","text":"<p>En l'aprenentatge no supervisat, l'algorisme no contempla etiquetes pr\u00e8vies ni respostes correctes. Nom\u00e9s rep dades i intenta descobrir patrons o grups per ell mateix. En l'exemple de les fotos, se tractaria de no dir-li quines s\u00f3n gats i quines s\u00f3n gossos, i que se n'adone que hi ha dos grups de fotos que comparteixen caracter\u00edstiques molt semblants i diferents a les de l'altre grup.</p> <p>En l'aprenentatge no supervisat utilitzem algorismes com:</p> <ul> <li>Clustering: Agrupa les dades en cl\u00fasters o grups basats en la similitud. Un exemple com\u00fa \u00e9s l'algorisme K-means, que divideix les dades en K grups basats en la dist\u00e0ncia entre els punts de dades. L'algorisme G-means \u00e9s una millora sobre K-means que busca agrupar les dades en K grups, on K \u00e9s un par\u00e0metre que l'usuari ha de definir. L'algorisme assigna cada punt de dades al grup m\u00e9s proper i actualitza els centres dels grups iterativament fins a aconseguir una converg\u00e8ncia.</li> <li>DBSCAN (Density-Based Spatial Clustering of Applications with Noise): \u00e9s un algorisme de clustering basat en la densitat que agrupa punts que estan densament connectats i marca els punts a\u00efllats com a soroll (outliers). T\u00e9 alguns avantatges sobre K-Means:</li> <li>Detecta clusters de forma arbitr\u00e0ria (no necess\u00e0riament esf\u00e8rics, com K-Means).</li> <li>No requereix que se especifique la quantitat de clusters pr\u00e8viament, com en K-Means.</li> <li>Mean Shift: \u00e9s un algorisme de clustering basat en la densitat que identifica els cl\u00fasters com a regions de m\u00e0xima densitat en l'espai de caracter\u00edstiques. L'algorisme busca els punts de m\u00e0xima densitat en l'espai de caracter\u00edstiques, sense suposar res sobre la forma dels cl\u00fasters. Fa l'estimaci\u00f3 del centre de cada cl\u00faster mitjan\u00e7ant una finestra de cerca que es mou cap a la direcci\u00f3 de m\u00e0xima densitat. El proc\u00e9s es repeteix fins que els centres dels cl\u00fasters convergeixen.</li> </ul> <p>Tot i que en certes fonts s'inclou la Reducci\u00f3 de dimensionalitat com a algorisme d'aprenentatge no supervisat, amb t\u00e8cniques com l'An\u00e0lisi de Components Principals (PCA), en realitat \u00e9s una forma de reduir la complexitat de les dades mantenint la major part de la informaci\u00f3 rellevant. Aix\u00f2 \u00e9s \u00fatil per visualitzar dades en espais de menor dimensi\u00f3 o per millorar l'efici\u00e8ncia dels models, simplificant-lo i reduint el temps d'entrenament. Per tant, seria m\u00e9s b\u00e9 una t\u00e8cnica de preprocessament de dades que un algorisme d'aprenentatge en si mateix.</p> <p></p>"},{"location":"u02/#aprenentatge-per-reforc","title":"Aprenentatge per refor\u00e7","text":"<p>En l'Aprenentatge per Refor\u00e7, com hem comentat abans al parlar del programa de Deep Mind, l'objectiu \u00e9s aprendre com mapejar situacions o accions per maximitzar una certa recompensa. Es tracta de entrenar agents mitjan\u00e7ant premi i c\u00e0stig, en funci\u00f3 de si l'acci\u00f3 ha estat beneficiosa o perjudicial, sense necessitat d'especificar com fer la tasca.</p> <p>Exemples: certs tipus de jocs, robots que aprenen a caminar o rob\u00f2tica industrial, sistemes de recomanaci\u00f3 que aprenen a suggerir contingut basat en les prefer\u00e8ncies dels usuaris.</p>"},{"location":"u02/#machine-learning-ml-vs-deep-learning-dl","title":"Machine Learning (ML) vS Deep Learning (DL)","text":"<p>El Machine Learning (ML) \u00e9s un subcamp de la intel\u00b7lig\u00e8ncia artificial que se centra en el desenvolupament d'algorismes i models que permeten a les m\u00e0quines aprendre a partir de dades. Quan estem parlant de Sistemes d'Aprenentatge Autom\u00e0tic podem dir que estem parlant de ML. Per la seua banda, el Deep Learning (DL) \u00e9s una branca del Machine Learning que utilitza xarxes neuronals profundes per modelar i resoldre problemes complexos. Ja veurem m\u00e9s endavant que les xarxes neuronals s\u00f3n una de les t\u00e8cniques m\u00e9s potents i utilitzades en l'aprenentatge autom\u00e0tic.</p>"},{"location":"u02/#diferencies-clau","title":"Difer\u00e8ncies clau","text":"<ul> <li>Estructura del model: ML pot utilitzar models m\u00e9s simples com arbres de decisi\u00f3 o regressi\u00f3 log\u00edstica, mentre que DL utilitza xarxes neuronals amb m\u00faltiples capes (profundes).</li> <li>Requeriments de dades: DL generalment necessita grans quantitats de dades etiquetades per entrenar models efectius, mentre que ML pot funcionar amb conjunts de dades m\u00e9s petits.</li> <li>Pot\u00e8ncia computacional: DL requereix m\u00e9s pot\u00e8ncia computacional i recursos d'GPU per entrenar models, mentre que ML pot ser m\u00e9s eficient en termes de recursos.</li> </ul> <p>El fet que el Deep Learning necessite de gran quantitats de dades \u00e9s el motiu pel qual tamb\u00e9 tenim els m\u00f2duls de Sistemes de Big Data i Big Data Aplicat. La possibilitat de treballar amb grans volums de dades, oferida per els sistemes de Big Data desenvolupats en les \u00faltimes d\u00e8cades, ha estat un factor clau en l'\u00e8xit actual del Deep Learning i la IA en general.</p> <p></p>"},{"location":"u02/#algunes-tecniques-de-deep-learning","title":"Algunes t\u00e8cniques de Deep Learning.","text":"<p>Algunes t\u00e8cniques i arquitectures comunes en el Deep Learning, que tamb\u00e9 anirem estudiant al llarg del m\u00f2dul, inclouen:</p> <ul> <li>Xarxes Neuronals Simples: la base del Deep Learning, consistixen en capes de neurones connectades entre si, on cada capa processa les dades i les transmet a la seg\u00fcent. Un exemple serien els perceptrons, que s\u00f3n xarxes neuronals amb una sola capa oculta.</li> <li>Xarxes Neuronals Profundes (DNN): xarxes neuronals amb m\u00faltiples capes ocultes que permeten modelar relacions complexes en les dades.</li> <li>Xarxes Neuronals Convolucionals (CNN): utilitzades principalment en el processament d'imatges, utilitzen operacions de convoluci\u00f3 per detectar caracter\u00edstiques espacials i patrons en les dades.</li> <li>Xarxes Neuronals Recurrentes (RNN): dissenyades per a dades seq\u00fcencials, com el text o les s\u00e8ries temporals, utilitzen connexions recurrents per capturar depend\u00e8ncies temporals.</li> <li>Xarxes Generatives Antagonistes (GAN): utilitzades per generar dades noves, com imatges o m\u00fasica, mitjan\u00e7ant dos models que competeixen entre si: un generador i un discriminador.</li> <li>Transformers: arquitectures que utilitzen mecanismes d'atenci\u00f3 per processar dades seq\u00fcencials, com el text, permetent una millor comprensi\u00f3 del context i les relacions entre les paraules.</li> <li>Transfer learning: t\u00e8cnica que permet utilitzar models pr\u00e8viament entrenats en tasques similars per millorar l'aprenentatge en una nova tasca, reduint el temps d'entrenament i millorant la precisi\u00f3.</li> <li>Fine tunning: ajustament de models preentrenats per adaptar-los a una tasca espec\u00edfica, millorant la precisi\u00f3 i reduint el temps d'entrenament.</li> </ul> <p>Tot i ser t\u00e8cniques de Deep Learning i, en alguns casos, utilitzar xarxes neuronals, les GAN i els Transformers els veurem en el m\u00f2dul de Models d'IA. Les GAN perqu\u00e8 s\u00f3n models generatius que no s'adapten exactament als algorismes que veurem en SAA, i els Transformers perqu\u00e8 s\u00f3n models que s'utilitzen principalment en el processament del llenguatge natural, un apartat del m\u00f2dul de MIA.</p>"},{"location":"u02/#machine-learning-i-estadistica","title":"Machine Learning i estad\u00edstica","text":"<p>Hi ha una connexi\u00f3 profunda entre l'Estad\u00edstica i l'Aprenentatge Autom\u00e0tic (Machine Learning). Segons Larry A. Wasserman, professor de la Carnegie Mellon, quan li van preguntar per les difer\u00e8ncies, va respondre: \"La resposta curta \u00e9s: cap. S'ocupen\u2026 de la mateixa pregunta: com aprenem a partir de les dades?\"</p> <p>Tot aix\u00f2, caldria especificar que:</p> <ul> <li>Estad\u00edstica tradicional: se centra en la infer\u00e8ncia estad\u00edstica formal (intervals de confian\u00e7a, proves d'hip\u00f2tesis, estimadors \u00f2ptims) en problemes de baixa dimensi\u00f3 (conjunts de dades menuts).</li> <li>Aprenentatge Autom\u00e0tic: es focalitza m\u00e9s en fer prediccions precises en altes dimensions (grans conjunts de dades).</li> </ul> <p>Ambdues disciplines busquen extraure coneixement de les dades i empren t\u00e8cniques similars. De fet, en la majoria d'ocasions cada pas en un projecte d'Aprenentatge Autom\u00e0tic requereix l'\u00fas d\u2019un m\u00e8tode estad\u00edstic, des de la comprensi\u00f3 de les dades fins a la interpretaci\u00f3 dels resultats.</p> <p>M\u00e9s endavant repassarem alguns conceptes b\u00e0sics d'estad\u00edstica que s\u00f3n fonamentals per entendre els SAA.</p>"},{"location":"u02/#components-i-fases-de-laprenentatge-automatic","title":"Components i fases de l'Aprenentatge Autom\u00e0tic","text":"<p>Hem de recordar que l'Aprenentatge Autom\u00e0tic (ML) dins del terreny de la intel\u00b7lig\u00e8ncia artificial se centra a desenvolupar sistemes capa\u00e7os d'aprendre autom\u00e0ticament a partir de dades, amb l\u2019objectiu de fer prediccions o prendre decisions sense programaci\u00f3 expl\u00edcita per a cada cas. Per tant, el proc\u00e9s necessita estar ben estructurat. Podem defiir per una banda els components principals que necessitaria un SAA, i per altra banda les fases que caldria seguir per a desenvolupar-lo.</p>"},{"location":"u02/#components-principals-dun-saa","title":"Components principals d'un SAA","text":"<p>Per entendre com funciona, podem identificar diversos components fonamentals. Per aclarir qu\u00e8 passa en cada fase, agafem com a exemple un sistema que apr\u00e9n a detectar si un correu electr\u00f2nic \u00e9s correu brossa (spam):</p> <ul> <li>Entrada (x): Les dades d\u2019entrada, tamb\u00e9 anomenades caracter\u00edstiques (features), s\u00f3n les propietats mesurables d\u2019una inst\u00e0ncia.</li> </ul> <p>\u2192 Exemple: nombre de vegades que apareix la paraula \"gratis\" en un correu.</p> <ul> <li>Eixida (y): \u00c9s el resultat que volem predir o classificar.</li> </ul> <p>\u2192 Exemple: \"spam\" o \"no spam\".</p> <ul> <li> <p>Funci\u00f3 objectiu (f: X \u2192 Y): \u00c9s la funci\u00f3 ideal que mapeja cada entrada a la seua eixida correcta. Aquesta funci\u00f3 \u00e9s desconeguda en la realitat (si la conegu\u00e9rem, podr\u00edem crear una soluci\u00f3 programada, un Model), per\u00f2 \u00e9s la que volem aproximar.</p> </li> <li> <p>Dades: S\u00f3n els registres hist\u00f2rics d'exemples d\u2019entrada i eixida coneguts.</p> </li> </ul> <p>\u2192 Exemple: una gran quantitat de correus etiquetats com spam o no spam.</p> <ul> <li>Hip\u00f2tesi (g: X \u2192 Y): \u00c9s la funci\u00f3 aproximada que el model apr\u00e9n a partir de les dades. Intenta assemblar-se al m\u00e0xim a la funci\u00f3 objectiu.</li> </ul> <p>El model que obtenim \u00e9s, de fet, la representaci\u00f3 matem\u00e0tica de la hip\u00f2tesi que el sistema ha apr\u00e8s a partir de l'experi\u00e8ncia (les dades).</p>"},{"location":"u02/#fases-del-proces-daprenentatge-automatic","title":"Fases del proc\u00e9s d'Aprenentatge Autom\u00e0tic","text":"<p>Tot el proc\u00e9s d'aprenentatge autom\u00e0tic es pot dividir en diverses fases, que poden variar lleugerament depenent del projecte, per\u00f2 que generalment inclouen:</p> <ol> <li> <p>Definici\u00f3 del problema: Comprendre i definir clarament el problema (empresarial, cient\u00edfic, etc.) que es vol resoldre.</p> </li> <li> <p>Recollida de dades: Obtenir les dades necess\u00e0ries per entrenar el model.</p> </li> <li> <p>Preprocessament de dades: Netejar i preparar les dades per a l'an\u00e0lisi. La recollida i preparaci\u00f3 de dades ocupa moltes vegades la major part del temps d'un projecte d'aprenentatge autom\u00e0tic.</p> </li> <li> <p>Neteja de dades: Eliminar valors nuls, duplicats o erronis.</p> </li> <li>Extracci\u00f3 de dades de qualitat: Seleccionar les dades rellevants per al problema.</li> <li> <p>Transformaci\u00f3 de dades: Convertir les dades a un format adequat per al model (normalitzaci\u00f3, codificaci\u00f3 de variables categ\u00f2riques, etc.).</p> </li> <li> <p>Selecci\u00f3 de caracter\u00edstiques: Escollir les caracter\u00edstiques m\u00e9s rellevants per al model.</p> </li> <li> <p>Entrenament del model: Utilitzar les dades d'entrenament per ajustar els par\u00e0metres del model. Normalment no utilitzarem totes les dades disponibles per l'entrenament, sin\u00f3 que les dividirem en un conjunt d'entrenament i un de validaci\u00f3. Aix\u00ed, el model pot aprendre de les dades d'entrenament i despr\u00e9s ser avaluat i validat (en el seu cas) amb les dades de validaci\u00f3.</p> </li> <li> <p>Avaluaci\u00f3 del model: Provar el model amb dades noves per avaluar-ne el rendiment. En general utilitzarem el 80% de les dades per a l'entrenament i el 20% restant per a la validaci\u00f3. Aix\u00ed, podem comprovar si el model ha apr\u00e8s correctament i si \u00e9s capa\u00e7 de generalitzar a dades noves. Es comparen les prediccions del model amb les etiquetes o resultats reals per calcular m\u00e8triques de rendiment com l'exactitud, la precisi\u00f3, el recall, etc.</p> </li> <li> <p>Ajust d'hiperpar\u00e0metres: Optimitzar els par\u00e0metres del model per millorar el seu rendiment. Aix\u00f2 pot incloure ajustar la complexitat del model, la taxa d'aprenentatge, el nombre d'iteracions, la profunditat d'un arbre de decisi\u00f3, etc.</p> </li> <li> <p>Validaci\u00f3 creuada: Una t\u00e8cnica per avaluar el rendiment del model en diferents subconjunts de dades.</p> </li> <li> <p>Grid search o Random search: T\u00e8cniques per trobar la millor combinaci\u00f3 d'hiperpar\u00e0metres.</p> </li> <li> <p>Desplegament: Implementar el model en un entorn de producci\u00f3.</p> </li> <li> <p>Monitoritzaci\u00f3 i manteniment: Supervisar el model en funcionament i actualitzar-lo segons siga necessari.</p> </li> </ol>"},{"location":"u02/#errors-frequents-en-laprenentatge-automatic","title":"Errors freq\u00fcents en l'Aprenentatge Autom\u00e0tic","text":"<p>Tot i que els algoritmes d'aprenentatge autom\u00e0tic poden ser molt potents, aplicar-los sense criteri pot ser contraproduent. Alguns errors comuns que es poden cometre en el proc\u00e9s d'aprenentatge autom\u00e0tic s\u00f3n:</p> <ul> <li>Respondre la pregunta incorrecta</li> <li>Recollir o utilitzar dades inadequades.</li> <li>Seleccionar malament l'algoritme per al problema.</li> <li>No entendre els biaixos o limitacions del model.</li> <li>No validar i optimitzar adequadament el model.</li> <li>Interpretar malament els resultats.</li> </ul>"},{"location":"u02/#quan-utilitzar-o-no-laprenentatge-automatic","title":"Quan utilitzar (o no) l'Aprenentatge Autom\u00e0tic","text":"<p>L'aprenentatge autom\u00e0tic ser\u00e0 apropiat principalment en estos casos:</p> <ul> <li>problemes que comporten conjunts de dades grans i complexos, on \u00e9s dif\u00edcil relacionar les diferents caracter\u00edstiques i establir un conjunt de regles heur\u00edstiques. Un exemple d'aquest tipus seria el filtre d'Spam que hem vist.</li> <li>problemes que comporten no nom\u00e9s conjunts grans de dades, sin\u00f2 de moltes caracter\u00edstiques a analitzar (el que es coneix com alta dimensionalitat), de manera que no \u00e9s senzill establir relacions entre elles. Un possible exemple seria l'an\u00e0lisi d\u2019informaci\u00f3 gen\u00e8tica en biologia molecular.</li> <li>problemes complexos, amb patrons no linials, on l'analista no sap determinar a simple vista una soluci\u00f3 a partir de la informaci\u00f3 existent. Alguns exemples poden ser la classificaci\u00f3 d'imatges, el reconeixement de d\u00edgits manuscrits o de veu.</li> <li>entorns que fluct\u00faen amb freq\u00fc\u00e8ncia, que s\u00f3n canviants amb el temps i per tant requereixen una adaptaci\u00f3 constant. Un exemple pot ser la predicci\u00f3 del tr\u00e0nsit de vehicles en temps real o el tr\u00e0fic de xarxa.</li> </ul>"},{"location":"u02/#ia-generativa","title":"IA Generativa","text":"<p>L'IA Generativa \u00e9s un subcamp de la intel\u00b7lig\u00e8ncia artificial que se centra en la creaci\u00f3 de contingut nou i original, com ara imatges, text, m\u00fasica o v\u00eddeos, mitjan\u00e7ant l'\u00fas d'algorismes d'aprenentatge autom\u00e0tic. A difer\u00e8ncia de la IA tradicional, que es basa en la classificaci\u00f3 o predicci\u00f3 de dades existents, l'IA generativa busca produir noves dades que segueixin les mateixes caracter\u00edstiques o patrons que les dades d'entrenament.</p> <p>Abans hem parlat els algorismes de Generative Adversarial Networks (GAN) i els Transformers. Serien algorismes que s'utilitzen com a t\u00e8cniques d'IA generativa. Aquestes t\u00e8cniques han revolucionat el camp de la IA, permetent la creaci\u00f3 de contingut de gran qualitat i realisme.</p>"},{"location":"u02/#eines-i-llenguatges-de-programacio-per-a-laprenentatge-automatic","title":"Eines i llenguatges de programaci\u00f3 per a l'Aprenentatge Autom\u00e0tic","text":"<p>Encara que se poden utilitzar molts llenguatges de programaci\u00f3 per a l'aprenentatge autom\u00e0tic, el m\u00e9s habitual \u00e9s Python. Ho \u00e9s b\u00e0sicament perqu\u00e8 ofereix una gran quantitat de biblioteques i eines que faciliten el desenvolupament de models d'aprenentatge autom\u00e0tic, com ara:</p> <ul> <li>NumPy: per al c\u00e0lcul num\u00e8ric, inform\u00e0tica cient\u00edfica i operacions amb arrays N-dimensionals.</li> <li>Matplotlib: per a la visualitzaci\u00f3 de dades.</li> <li>Seaborn: per a la visualitzaci\u00f3 estad\u00edstica de dades.</li> <li>Pandas: per a la manipulaci\u00f3 i an\u00e0lisi de dades (DataFrames).</li> <li>Scikit-learn: per a l'aprenentatge autom\u00e0tic tradicional, tant supervisat com no supervisat (preprocessament, classificaci\u00f3, regressi\u00f3, clustering, avaluaci\u00f3, etc.).</li> <li>TensorFlow i PyTorch: per a l'aprenentatge profund (deep learning) i la creaci\u00f3 de xarxes neuronals.</li> <li>Keras: una API de Python per a la creaci\u00f3 de models d'aprenentatge profund, que pot utilitzar TensorFlow o Theano com a backend. Redueix la quantitat de codi necessari per crear models d'aprenentatge profund i facilita la construcci\u00f3 i entrenament de xarxes neuronals.</li> </ul> <p>Els entorns de desenvolupament m\u00e9s comuns inclouen Jupyter Notebooks, Google Colab i VSCode/PyCharm amb entorns de tipus Conda.</p> <p>Conda \u00e9s un gestor d'entorns i paquets que permet crear entorns a\u00efllats per a projectes de Python, facilitant la gesti\u00f3 de depend\u00e8ncies i versions de biblioteques. Aix\u00ed evitem problemes de compatibilitat entre projectes i podem tenir diferents versions de les mateixes biblioteques en diferents entorns.</p>"},{"location":"u03/","title":"Preprocessament de les dades. Estad\u00edstica.","text":"<p>En la unitat anterior hem vist els conceptes b\u00e0sics de la intel\u00b7lig\u00e8ncia artificial i els sistemes d'aprenentatge autom\u00e0tic. Hem comentat les diferents fases per les quals passa un projecte d'aprenentatge autom\u00e0tic. Ara ens centrarem en el preprocessament de les dades, un pas fonamental en el desenvolupament dels models.</p>"},{"location":"u03/#que-es-el-preprocessament-de-les-dades","title":"Qu\u00e8 \u00e9s el preprocessament de les dades?","text":"<p>El preprocessament de les dades \u00e9s el conjunt d'operacions que es realitzen sobre les dades brutes per preparar-les per a l'an\u00e0lisi i l'entrenament dels models d'aprenentatge autom\u00e0tic. Aquest pas \u00e9s crucial perqu\u00e8 la qualitat de les dades influeix directament en el rendiment del model. Si treballem directament sobre les dades brutes tenim el risc de crear models poc precisos o fins i tot erronis. Els motius principals per realitzar el preprocessament de les dades s\u00f3n:</p> <ul> <li>Eliminar el soroll: Les dades brutes sovint contenen informaci\u00f3 irrellevant o sorollosa que pot distorsionar els resultats del model.</li> <li>Millorar la qualitat de les dades: Les dades brutes poden incloure valors nuls, duplicats o fins i tot erronis que poden afectar negativament els resultats del model.</li> <li>Facilitar l'an\u00e0lisi: Les dades preprocessades s\u00f3n m\u00e9s f\u00e0cils d'analitzar i interpretar, ja que estan en un format m\u00e9s net i estructurat.</li> <li>Optimitzar el rendiment del model: Un bon preprocessament pot reduir el temps d'entrenament i millorar la precisi\u00f3 del model, ja que les dades estan preparades de manera adequada per a l'aprenentatge autom\u00e0tic.</li> <li>Adaptar les dades al model: Alguns models requereixen que les dades estiguin en un format espec\u00edfic, com ara valors normalitzats o codificats. El preprocessament ajuda a adaptar les dades a aquests requisits.  </li> </ul>"},{"location":"u03/#etapes-del-preprocessament-de-les-dades","title":"Etapes del preprocessament de les dades","text":"<p>El primer pas, l\u00f2gicament, seria recollir les dades. Hem de trobar una font de dades fiable i rellevant per al nostre projecte, o b\u00e9 generar-les a trav\u00e9s d'observacions o simulacions. Un cop tenim les dades, \u00e9s quan comen\u00e7a realment el preprocessament.</p> <p>El preprocessament de les dades pot incloure diverses etapes, depenent del tipus de dades i del problema a resoldre. Algunes de les etapes m\u00e9s comunes s\u00f3n:</p> <ul> <li>Exploraci\u00f3 de dades: An\u00e0lisi inicial per comprendre la distribuci\u00f3, les tend\u00e8ncies i les anomalies de les dades.</li> <li>Neteja de dades: Eliminaci\u00f3 de valors nuls, duplicats o erronis.</li> <li>Transformaci\u00f3 de dades: Escalatge, normalitzaci\u00f3 o codificaci\u00f3 de les dades.</li> <li>Selecci\u00f3 de caracter\u00edstiques: Tria de les variables m\u00e9s rellevants per al model (i eliminaci\u00f3 de les irrellevants).</li> <li>Divisi\u00f3 de dades: Separaci\u00f3 de les dades en conjunts d'entrenament i prova.</li> </ul> <p>El preprocessament de les dades \u00e9s essencial per garantir que els models d'aprenentatge autom\u00e0tic funcionen de manera \u00f2ptima. Un bon preprocessament pot millorar la precisi\u00f3 del model, reduir el temps d'entrenament i evitar problemes com l'overfitting. A m\u00e9s, ajuda a identificar i corregir errors en les dades abans que afecten el rendiment del model.</p> <p>L'overfitting \u00e9s un problema com\u00fa en l'aprenentatge autom\u00e0tic on el model s'ajusta massa als detalls i al soroll de les dades d'entrenament, perdent la capacitat de generalitzar a noves dades. Per posar un exemple concret, si entrenem un model per recon\u00e8ixer gats i gossos amb imatges que nom\u00e9s contenen animals d'un color espec\u00edfic, el model pot aprendre a identificar nom\u00e9s aquells colors i no generalitzar b\u00e9 a altres colors d'animals.</p> <p>En resum, determinats aspectes seran clau en el tractament de les dades:</p> <ul> <li>registres incomplets (missing values)</li> <li>registres amb valors an\u00f2mals (outliers) que poden influir en l'an\u00e0lisi</li> <li>estandaritzaci\u00f3 de les dades, per a que tots estiguen en una mateixa escala</li> <li>reducci\u00f3 de la dimensionalitat o selecci\u00f3 de variables significatives per al problema a resoldre si el conjunt de dades \u00e9s molt gran o divers</li> </ul>"},{"location":"u03/#repas-estadistica","title":"Rep\u00e0s estad\u00edstica","text":"<p>Per a poder realitzar un bon preprocessament de les dades, \u00e9s important tenir coneixements b\u00e0sics d'estad\u00edstica. Aix\u00f2 ens permetr\u00e0 entendre millor les caracter\u00edstiques de les dades i aplicar les t\u00e8cniques adequades per al seu tractament. Sobretot anem a necessitar eines d'estad\u00edstica descriptiva. L'estad\u00edstica descriptiva \u00e9s una branca de les matem\u00e0tiques que s'encarrega principalment de descriure un conjunt de dades, per tal de facilitar-ne la seua comprensi\u00f3.</p> <p>Dins l'estad\u00edstica descriptiva distingim dos tipus de mesures, les de tend\u00e8ncia central o centralitat i les de variabilitat o dispersi\u00f3. Les mesures de tend\u00e8ncia central s\u00f3n aquelles que busquen identificar un valor representatiu dins del conjunt de dades, o veure com s'agrupen les dades al voltant d'un punt central. Les mesures de dispersi\u00f3 indiquen com de disperses o agrupades estan les dades al voltant de les mesures de tend\u00e8ncia central. </p> <p>Per exemple, imagineu que les notes d'una classe s\u00f3n 1, 1, 2, 2, 3, 5, 5, 9, 9, 9, 10.</p> <p>La mitjana seria 5,09, o siga pr\u00e0cticament 5 La mediana seria 5, o siga el valor que separa la meitat superior de la meitat inferior La moda seria 9, o siga el valor que apareix amb m\u00e9s freq\u00fc\u00e8ncia</p> <p>Per\u00f2 de totes estes mesures, no hi ha cap que ens diga que hi ha quatre notes excel\u00b7lents i la resta tenen un 5 o han susp\u00e9s. Aix\u00f2 ens ho han de dir les mesures de dispersi\u00f3. La mitjana i la mediana tamb\u00e9 serien 5 si tot l'alumnat tinguera un 5, i la situaci\u00f3 seria diferent i necessitaria una altra an\u00e0lisi.</p> <p>Anem a repassar les mesures m\u00e9s comunes d'estad\u00edstica descriptiva:</p> <p>de tend\u00e8ncia central</p> <ul> <li>Mitjana: La suma de tots els valors dividida pel nombre de valors.</li> <li>Mediana: El valor que separa la meitat superior de la meitat inferior d'un conjunt de dades. \u00c9s \u00fatil per identificar la tend\u00e8ncia central en dades amb outliers. En eixe cas, seria una mesura de tend\u00e8ncia central de vegades m\u00e9s robusta que la mitjana.</li> <li>Moda: El valor que apareix amb m\u00e9s freq\u00fc\u00e8ncia en un conjunt de dades. Pot haver-hi m\u00e9s d'una moda en un conjunt de dades. \u00c9s especialment \u00fatil en dades m\u00e9s qualitatives o categ\u00f2riques.</li> </ul> <p>de dispersi\u00f3</p> <ul> <li>Rang: La difer\u00e8ncia entre el valor m\u00e0xim i el m\u00ednim d'un conjunt de dades. Indica l'amplitud de la variaci\u00f3.</li> <li>Desviaci\u00f3 est\u00e0ndard: Mesura de la dispersi\u00f3 dels valors respecte a la mitjana. Una desviaci\u00f3 est\u00e0ndard alta indica que els valors estan molt dispersos. Se calcula sumant les difer\u00e8ncies entre cada valor i la mitjana i fent la mitjana d'eixes difer\u00e8ncies.</li> <li>Varian\u00e7a: Mesura de la dispersi\u00f3 dels valors respecte a la mitjana. \u00c9s el quadrat de la desviaci\u00f3 est\u00e0ndard i indica com de dispersos estan els valors al voltant de la mitjana. Se calcula fent la mateixa operaci\u00f3 que per a la desviaci\u00f3 est\u00e0ndard, per\u00f2 elevant al quadrat les difer\u00e8ncies abans de sumar-les.</li> </ul> <p>La f\u00f3rmula de la varian\u00e7a per a una mostra \u00e9s:</p> <p>$$ \\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 $$</p> <p>On $\\sigma^2$ \u00e9s la varian\u00e7a, $n$ \u00e9s el nombre de valors, $x_i$ cada valor i $\\bar{x}$ la mitjana.</p> <p>La desviaci\u00f3 est\u00e0ndard tamb\u00e9 pot calcular-se com l'arrel quadrada de la varian\u00e7a:</p> <p>$$\\sigma = \\sqrt{\\sigma^2}$$</p> <p>Tot i que la varian\u00e7a i la desviaci\u00f3 est\u00e0ndard s\u00f3n molt similars, la desviaci\u00f3 est\u00e0ndard \u00e9s m\u00e9s f\u00e0cil d'interpretar perqu\u00e8 est\u00e0 en les mateixes unitats que les dades originals, mentre que la varian\u00e7a \u00e9s m\u00e9s \u00fatil per a c\u00e0lculs matem\u00e0tics i estad\u00edstics.</p> <p></p> <ul> <li>Quartils i Rang interquartilic: Divisi\u00f3 dels valors en quatre parts iguals. El primer quartil (Q1) \u00e9s el valor que separa el 25% inferior del conjunt de dades, el segon quartil (Q2) \u00e9s la mediana i el tercer quartil (Q3) \u00e9s el valor que separa el 75% inferior del conjunt de dades. Els quartils avaluen la dispersi\u00f3 i simetria de les dades. El rang interquartilic (IQR) \u00e9s la difer\u00e8ncia entre el tercer quartil i el primer quartil, i mesura la dispersi\u00f3 dels valors centrals del conjunt de dades eliminant els valors molt alts (quart quartil) i molt baixos (primer quartil).</li> </ul> <p></p> <p>Fixeu-vos que nom\u00e9s hi ha 3 quartils (Q1, Q2 i Q3). Aix\u00f2 pot portar a confusi\u00f3 amb la paraula \"quartil\", que sembla indicar que hi ha quatre divisions. En realitat s\u00ed que hi ha quatre divisions, per\u00f2 la paraula \"quartil\" fa refer\u00e8ncia als punts que separen les divisions, per aix\u00f2 nom\u00e9s hi ha tres quartils.</p> <p>Per a qu\u00e8 aprofiten els quartils en estad\u00edstica? Doncs, com hem vist, \u00e9s una altra forma de veure com de disperses estan les dades. Si la difer\u00e8ncia entre Q1 i Q3 \u00e9s gran, vol dir que hi ha molta dispersi\u00f3 en les dades centrals. Si la difer\u00e8ncia \u00e9s petita, vol dir que les dades centrals estan m\u00e9s agrupades.</p> <p>Hi ha una altra mesura que \u00e9s important per a l'an\u00e0lisi de dades, encara que no pertany a les mesures de tend\u00e8ncia central o dispersi\u00f3, que \u00e9s la correlaci\u00f3. La correlaci\u00f3 ens troba la relaci\u00f3 entre dues variables. Eixa relaci\u00f3 pot ser positiva (ambdues variables augmenten juntes), negativa (quan una augmenta l'altra disminueix) o nul\u00b7la (no hi hap relaci\u00f3 entre les variables). \u00c9s \u00fatil quan volem saber si dues variables estan relacionades i, si \u00e9s aix\u00ed, com ho estan. Aix\u00f2 ser\u00e0 important quan comencem a entrenar models d'aprenentatge autom\u00e0tic, perqu\u00e8 ens ajudar\u00e0 a seleccionar les variables m\u00e9s rellevants per al model.</p>"},{"location":"u03/#mesures-destadistica-en-python","title":"Mesures d'estad\u00edstica en Python","text":"<p>Python ofereix diverses biblioteques per al c\u00e0lcul d'estad\u00edstiques descriptives, com ara NumPy, Pandas i SciPy. Aquestes biblioteques proporcionen funcions per calcular les mesures de tend\u00e8ncia central i dispersi\u00f3 de manera eficient. En el m\u00f2dul de Programaci\u00f3 veureu com utilitzar-les. Ac\u00ed simplement oferim uns quants exemples b\u00e0sics:</p> <pre><code>import numpy as np # Biblioteca per al c\u00e0lcul num\u00e8ric\nimport pandas as pd # Biblioteca per al treball amb dades estructurades\n# Creem un conjunt de dades d'exemple, per exemple el que hem vist abans de les notes       \ndata = [1, 1, 2, 2, 3, 5, 5, 9, 9, 9, 10]\n# Convertim la llista a un array de NumPy\ndata_array = np.array(data)\n# Calculem la mitjana\nmean = np.mean(data_array)\n# Calculem la mediana\nmedian = np.median(data_array)\n# Calculem la moda\nmode = pd.Series(data).mode()[0]  # Utilitzem Pandas per calcular la moda, perqu\u00e8 NumPy no t\u00e9 una funci\u00f3 directa\n# Calculem la desviaci\u00f3 est\u00e0ndard\nstd_dev = np.std(data_array)\n# Calculem la varian\u00e7a\nvariance = np.var(data_array)\n# Calculem el rang\ndata_range = np.max(data_array) - np.min(data_array)\n# Calculem els quartils\nq1 = np.percentile(data_array, 25)  # Primer quartil\nq2 = np.percentile(data_array, 50)  # Mediana\nq3 = np.percentile(data_array, 75)  # Tercer quartil\n# Calculem el rang interquartilic\niqr = q3 - q1\n\n# No hem calculat la correlaci\u00f3 perqu\u00e8 nom\u00e9s tenim una variable que \u00e9s la nota.\n\n# Mostrem els resultats\n# Recordem les dades de l'exemple\nprint(\"Dades:\", data)\nprint(\"Mesures d'estad\u00edstica descriptiva:\")\nprint(f\"Mitjana: {mean}\")\nprint(f\"Mediana: {median}\")\nprint(f\"Moda: {mode}\")\nprint(f\"Desviaci\u00f3 est\u00e0ndard: {std_dev}\")\nprint(f\"Varian\u00e7a: {variance}\")\nprint(f\"Rang: {data_range}\")\nprint(f\"Quartil 1: {q1}\")\nprint(f\"Quartil 2: {q2}\")\nprint(f\"Quartil 3: {q3}\")\nprint(f\"Rang interquartilic: {iqr}\")\n\n</code></pre> <p>Veiem la sortida esperada del codi anterior:</p> <pre><code>Dades: [1, 1, 2, 2, 3, 5, 5, 9, 9, 9, 10]\nMesures d'estad\u00edstica descriptiva:\nMitjana: 5.090909090909091\nMediana: 5.0\nModa: 9\nDesviaci\u00f3 est\u00e0ndard: 2.516611478423583\nVarian\u00e7a: 6.3478260869565215\nRang: 9\nQuartil 1: 2.0\nQuartil 2: 5.0\nQuartil 3: 9.0\nRang interquartilic: 7.0\n</code></pre>"},{"location":"u03/#interpetacio-de-les-mesures","title":"Interpetaci\u00f3 de les mesures","text":"<p>Ara que tenim les mesures d'estad\u00edstica descriptiva, podem interpretar els resultats:</p> <ul> <li>Mitjana: La mitjana \u00e9s 5,09, que indica que la nota mitjana de la classe \u00e9s aproximadament un 5. Molt justet, per\u00f2 aprovat.</li> <li>Mediana: La mediana \u00e9s 5, el que donaria a entendre (si no tenim m\u00e9s informaci\u00f3) que la meitat de l'alumnat ha aprovat i l'altra meitat ha susp\u00e9s.</li> <li>Moda: La moda \u00e9s 9, el que indica que la nota m\u00e9s freq\u00fcent \u00e9s un 9, i per tant hi ha un grup d'alumnes que ha obtingut una nota alta.</li> <li>Desviaci\u00f3 est\u00e0ndard: La desviaci\u00f3 est\u00e0ndard \u00e9s 2,52, el que indica que les notes estan moderadament disperses al voltant de la mitjana. Aix\u00f2 vol dir que hi ha una variabilitat significativa en les notes dels alumnes, encara que no \u00e9s exagerada</li> <li>Varian\u00e7a: La varian\u00e7a \u00e9s 6,35, que \u00e9s una mesura de la dispersi\u00f3 dels valors respecte a la mitjana. Una varian\u00e7a m\u00e9s alta indica una major variabilitat en les notes. En aquest cas el valor \u00e9s moderat, la qual cosa confirma que hi ha una variabilitat significativa per\u00f2 no extrema.</li> <li>Rang: El rang \u00e9s 9, que \u00e9s la difer\u00e8ncia entre la nota m\u00e9s alta (10) i la m\u00e9s baixa (1). Aix\u00f2 indica que hi ha una gran difer\u00e8ncia de rendiment en les notes dels alumnes.</li> <li>Quartils: El primer quartil (Q1) \u00e9s 2, el segon quartil (Q2) \u00e9s 5 i el tercer quartil (Q3) \u00e9s 9. Aix\u00f2 indica que el 25% dels alumnes tenen notes iguals o inferiors a 2, el 50% tenen notes iguals o inferiors a 5 i el 75% tenen notes iguals o inferiors a 9.</li> <li>Rang interquartilic (IQR): L'IQR \u00e9s 7, que es calcula com la difer\u00e8ncia entre el tercer quartil (Q3) i el primer quartil (Q1). Aix\u00f2 indica que hi ha una variabilitat significativa en les notes dels alumnes, ja que la majoria de les notes es troben dins d'aquest rang.</li> </ul> <p>En resum, juntant totes les variables s\u00ed que hi ha una dispersi\u00f3 important en les notes. El grup est\u00e0 molt polaritzat i caldria prendre mesures per a millorar el rendiment dels alumnes que tenen notes m\u00e9s baixes, i segurament tamb\u00e9 per a refor\u00e7ar el rendiment dels alumnes que tenen notes m\u00e9s altes, per a que no es relaxin i continuen millorant.</p>"},{"location":"u03/#distribucio-de-les-dades","title":"Distribuci\u00f3 de les dades","text":"<p>La distribuci\u00f3 de les dades \u00e9s una altra caracter\u00edstica important a l'hora de realitzar el preprocessament. La distribuci\u00f3 ens indica com es distribueixen els valors d'una variable en un conjunt de dades. Hi ha diverses distribucions comunes, com ara la normal, la uniforme, la binomial o l'exponencial, entre altres.</p> <p>La distribuci\u00f3 normal o distribuci\u00f3 Gaussiana \u00e9s una de les m\u00e9s importants en estad\u00edstica i s'utilitza sovint com a model per a moltes variables naturals. T\u00e9 una forma de campana m\u00e9s o menys sim\u00e9trica al voltant de la mitjana (la majoria dels valors es troben a prop de la mitjana, i la probabilitat disminueix a mesura que ens allunyem d'ella).</p> <p></p> <p>La distribuci\u00f3 uniforme \u00e9s una distribuci\u00f3 on tots els valors tenen la mateixa probabilitat d'apar\u00e8ixer. \u00c9s \u00fatil quan volem modelar situacions on no hi ha prefer\u00e8ncia per cap valor en particular. Per exemple, llan\u00e7ar un dau on tots els valors (1-6) tenen la mateixa probabilitat d'apar\u00e8ixer.</p> <p></p> <p>La distribuci\u00f3 binomial \u00e9s una distribuci\u00f3 discreta que modela el nombre d'\u00e8xits en un nombre fix de proves independents, on cada prova t\u00e9 dues possibles resultats (\u00e8xit o frac\u00e0s). \u00c9s \u00fatil per a situacions com ara el nombre d'encerts en un test de preguntes de resposta m\u00faltiple. En general t\u00e9 una forma asim\u00e8trica, depenent de la probabilitat d'\u00e8xit (p). Si p \u00e9s 0.5, la distribuci\u00f3 \u00e9s sim\u00e8trica i per tant s'assembla a una distribuci\u00f3 normal.</p> <p></p> <p>La distribuci\u00f3 exponencial \u00e9s una distribuci\u00f3 cont\u00ednua que modela el temps entre esdeveniments en un proc\u00e9s. En general t\u00e9 una c\u00faa llarga en un extrem i decau r\u00e0pidament en l'altre extrem. \u00c9s \u00fatil per a situacions com ara el temps entre trucades en un call center o el temps entre arribades de clients a una botiga.</p> <p></p> Distribuci\u00f3 Tipus Par\u00e0metres Forma Exemple Binomial Discreta n (nombre de proves), p (prob. d'\u00e8xit) Asim\u00e8trica (dep\u00e8n de p) Nombre d'encerts en un test de 10 preguntes amb p = 0.5 Exponencial Cont\u00ednua \u03bb (lambda, taxa d'esdeveniments) Asim\u00e8trica (positiva) Temps entre trucades en un call center Normal Cont\u00ednua \u03bc (mitjana), \u03c3 (desviaci\u00f3 t\u00edpica) Sim\u00e8trica, forma de campana Al\u00e7ades de persones en una poblaci\u00f3 Uniforme Cont\u00ednua a (m\u00ednim), b (m\u00e0xim) Plana (prob. constant) Valor aleatori entre 0 i 1 (per sortejos) <p>Con\u00e9ixer com es distribueixen les dades \u00e9s de gran import\u00e0ncia per tal de crear uns o altres models. Per exemple, si les dades segueixen una distribuci\u00f3 normal podem utilitzar t\u00e8cniques estad\u00edstiques que assumeixen aquesta normalitat. Si les dades no segueixen una distribuci\u00f3 normal, haurem d'optar entre fer algun tipus de transformaci\u00f3 o utilitzar altres models que no necessiten una distribuci\u00f3 normal. Ja veurem quines transformacions podem aplicar en cada cas.</p>"},{"location":"u03/#distribucions-en-python","title":"Distribucions en Python","text":"<p>Python tamb\u00e9 ofereix diverses biblioteques per treballar amb distribucions de dades, com ara NumPy, SciPy i Matplotlib. Aquestes biblioteques proporcionen classes i m\u00e8todes per generar dades aleat\u00f2ries segons diferents distribucions i per visualitzar-les. </p> <p>A continuaci\u00f3, un exemple de com generar dades aleat\u00f2ries segons diferents distribucions i visualitzar-les:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n# Configuraci\u00f3 de la figura\nplt.figure(figsize=(12, 8))\n# Generem dades aleat\u00f2ries per a cada distribuci\u00f3\n# Distribuci\u00f3 normal\nnormal_data = np.random.normal(loc=0, scale=1, size=1000)  # loc \u00e9s la mitjana, scale \u00e9s la desviaci\u00f3 est\u00e0ndard, size \u00e9s el nombre de dades\n# Distribuci\u00f3 uniforme\nuniform_data = np.random.uniform(low=0, high=1, size=1000)  # low \u00e9s el m\u00ednim, high \u00e9s el m\u00e0xim\n# Distribuci\u00f3 binomial\nbinomial_data = np.random.binomial(n=10, p=0.5, size=1000)  # n \u00e9s el nombre de proves, p \u00e9s la probabilitat d'\u00e8xit\n# Distribuci\u00f3 exponencial\nexponential_data = np.random.exponential(scale=1, size=1000)  # scale \u00e9s l'invers de la taxa d'esdeveniments. Un valor 1 vol dir que esperem una taxa d'esdevinents de 1 per unitat de temps. Un valor 5 vol dir que esperem una taxa d'esdeveniments de 0.2 (1/5) per unitat de temps.\n# Creem un subplot per a cada distribuci\u00f3\nplt.subplot(2, 2, 1)\nplt.hist(normal_data, bins=30, density=True, alpha=0.5, color='b')\nplt.title('Distribuci\u00f3 Normal')\nplt.xlabel('Valor')\nplt.ylabel('Densitat')\nplt.subplot(2, 2, 2)\nplt.hist(uniform_data, bins=30, density=True, alpha=0.5, color='g')\nplt.title('Distribuci\u00f3 Uniforme')\nplt.xlabel('Valor')\nplt.ylabel('Densitat')\nplt.subplot(2, 2, 3)\nplt.hist(binomial_data, bins=30, density=True, alpha=0.5, color='r')\nplt.title('Distribuci\u00f3 Binomial')\nplt.xlabel('Valor')\nplt.ylabel('Densitat')\nplt.subplot(2, 2, 4)\nplt.hist(exponential_data, bins=30, density=True, alpha=0.5, color='y')\nplt.title('Distribuci\u00f3 Exponencial')\nplt.xlabel('Valor')\nplt.ylabel('Densitat')\n# Mostrem la figura\nplt.tight_layout()\nplt.show()  \n</code></pre> <p>Executeu el codi anterior en un quadern Jupyter o en un entorn Python per veure les gr\u00e0fiques de les diferents distribucions. Cada gr\u00e0fica mostra la distribuci\u00f3 de les dades generades aleat\u00f2riament segons el tipus de distribuci\u00f3 especificat. Compareu els resultats amb les gr\u00e0fiques d'exemple que hem vist abans en la unitat.</p>"},{"location":"u03/#regla-empirica-de-la-distribucio-normal","title":"Regla emp\u00edrica de la distribuci\u00f3 normal","text":"<p>La regla emp\u00edrica, tamb\u00e9 coneguda com a regla 68-95-99.7, \u00e9s una guia emp\u00edrica que descriu com es distribueixen les observacions en una distribuci\u00f3 normal. Aquesta regla \u00e9s \u00fatil per a entendre la dispersi\u00f3 de les dades en una distribuci\u00f3 normal i proporciona estimacions aproximades de la proporci\u00f3 de dades dins de determinats intervals al voltant de la mitjana.</p> <p>La regla emp\u00edrica estableix el seg\u00fcent:</p> <p></p> <p>\u00c9s a dir, que en una distribuci\u00f3 normal aproximadament el 68% de les observacions es troben dins d'una desviaci\u00f3 t\u00edpica de la mitjana, el 95% de les observacions dins de dues desviacions t\u00edpiques de la mitjana, i el 99.7%  dins de tres desviacions t\u00edpiques de la mitjana.</p> <p></p>"},{"location":"u03/#conceptes-matematics-de-la-distribucio-normal","title":"Conceptes matem\u00e0tics de la distribuci\u00f3 normal","text":"<p>Per a poder treballar amb distribucions normals, hem d'entendre alguns conceptes matem\u00e0tics i nomenclatura relacionada amb aquesta distribuci\u00f3.</p> <p>Poblaci\u00f3 i mostra poblacional</p> <p>En estad\u00edstica, quan parlem de poblaci\u00f3 ens refereim a tot el conjunt d'individus o elements d'observaci\u00f3 que s'estudien en un context particular. Segons aquest context, la poblaci\u00f3 pot ser finita o infinita (tan gran que es desconeix el nombre exacte, com per exemple tota la poblaci\u00f3 del planeta).</p> <p>Quan volem fer un estudi sobre una poblaci\u00f3 concreta, sobretot si \u00e9s molt gran i no podem estudiar individu per individu, el que es fa \u00e9s agafar una mostra representativa de la poblaci\u00f3, la qual anomenem mostra poblacional.</p> <p>Si la mostra poblacional \u00e9s suficientment representativa de la poblaci\u00f3, ens permetr\u00e0 realitzar infer\u00e8ncies sobre la poblaci\u00f3 completa. \u00c9s a dir, que les conclussions que obtinguem sobre la mostra poblacional seran aplicables tamb\u00e9 a tota la poblaci\u00f3.</p> <p>Variables aleat\u00f2ries i distribucions de probabilitat</p> <p>Una variable aleat\u00f2ria es defineix com una funci\u00f3 que assigna valors num\u00e8rics als resultats d'un experiment o als elements d'una poblaci\u00f3, transformant el resultat de les observacions en quantitats. Aquestes variables aleat\u00f2ries s\u00f3n utilitzades per descriure i quantificar la variabilitat o la incertesa en els resultats d'un experiment o en les caracter\u00edstiques d'una poblaci\u00f3, i poden ser discretes (com els resultats de llan\u00e7ar un dau) o cont\u00ednues (com una medici\u00f3 de la temperatura).</p> <p>Formalment, diguem que una variable aleat\u00f2ria es una funci\u00f3 definida sobre un espai de probabilitat. Al final, \u00e9s una eina matem\u00e0tica que ens permet treballar amb els resultats d'un estudi o una poblaci\u00f3 en termes num\u00e8rics.</p> <p>Una distribuci\u00f3 de probabilitat \u00e9s una funci\u00f3 matem\u00e0tica que descriu la probabilitat de cada possible valor d'una variable aleat\u00f2ria. Aquesta distribuci\u00f3 pot ser discreta (per a variables aleat\u00f2ries discretes) o cont\u00ednua (per a variables aleat\u00f2ries cont\u00ednues). La distribuci\u00f3 de probabilitat indica com estan distribuides les probabilitats entre els diferents valors possibles de la variable i permet calcular la probabilitat que la variable aleat\u00f2ria prenga valors en determinats intervals.</p> <p>La funci\u00f3 de densitat de probabilitat proporciona una representaci\u00f3 matem\u00e0tica de la variabilitat i la incertesa associades a aquesta variable aleat\u00f2ria en una poblaci\u00f3 o mostra poblacional, i pren generalment la forma d\u2019una campana de Gauss.</p> <p>L\u2019expressi\u00f3 matem\u00e0tica que descriu aquesta funci\u00f3 de densitat de probabilitat \u00e9s:</p> <p>$$f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}$$</p> <p>On:</p> <ul> <li>$f(x)$ \u00e9s la funci\u00f3 de densitat de probabilitat.</li> <li>$\\mu$ \u00e9s la mitjana de la distribuci\u00f3.</li> <li>$\\sigma$ \u00e9s la desviaci\u00f3 est\u00e0ndard de la distribuci\u00f3.</li> <li>$e$ \u00e9s la base del logaritme natural (aproximadament 2.71828).</li> </ul>"},{"location":"u04/","title":"Aprenentatge supervisat","text":"<p>En l'aprenentatge supervisat, el model s'entrena amb un conjunt de dades etiquetades, \u00e9s a dir, dades que ja contenen la resposta correcta. L'objectiu \u00e9s que el model aprenga a fer prediccions o classificacions basades en aquestes dades. Les dades d'entrada s'anomenen features o atributs, mentre que les dades correctes de sortida s'anomenen etiquetes o targets.</p> <p>En este cas \u00e9s quan dividim el dataset en un conjunt d'entrenament i un conjunt de prova. El conjunt d'entrenament s'utilitza per ajustar el model (li subministrem les dades amb els seus atributs i tamb\u00e9 les eixides o etiquetes correctes), mentre que el conjunt de prova (nom\u00e9s amb els atributs) s'utilitza per avaluar-ne el rendiment del model entrenat.</p> <p>Un exemple on podr\u00edem utilitzar algorismes d'aprenentatge supervisat podria ser la classificaci\u00f3 de correus electr\u00f2nics com a spam o no spam, on els correus estan etiquetats pr\u00e8viament. O tamb\u00e9 la predicci\u00f3 del preu d'una casa basada en caracter\u00edstiques com la ubicaci\u00f3, la superf\u00edcie o l'antiguitat de la propietat.</p>"},{"location":"u04/#algorismes-basics-daprenentatge-supervisat","title":"Algorismes b\u00e0sics d'aprenentatge supervisat","text":"<p>Recordeu que els algorismes d'aprenentatge supervisat se poden classificar en dos grups: regressi\u00f3 i classificaci\u00f3.</p> <p></p> <p>Els algorismes de classificaci\u00f3 s'utilitzen per assignar etiquetes o classes a les dades d'entrada. L'objectiu \u00e9s predir la classe a la qual pertany una nova observaci\u00f3 basant-se en un conjunt de dades d'entrenament. Per exemple:</p> <ul> <li>un correu \u00e9s spam o no (bin\u00e0ria)</li> <li>una persona t\u00e9 una malaltia o no (bin\u00e0ria)</li> <li>a quin grup o categoria pertany un element (multiclasse, si hi ha m\u00e9s de dos grups)</li> </ul> <p>Els algorismes de classificaci\u00f3 t\u00edpics dins de l'aprenentatge supervisat s\u00f3n:</p> <ul> <li>Arbres de decisi\u00f3</li> <li>Random Forest</li> <li>K-Nearest Neighbors (KNN)</li> <li>Support Vector Machines (SVM)</li> <li>Naive Bayes i les seues diferents variacions</li> </ul> <p>Tamb\u00e9 podem incloure com algorisme de classificaci\u00f3 la regressi\u00f3 log\u00edstica. Tot i utilitzar la regressi\u00f3 lineal per predir probabilitats, en general s'utilitzen per problemes de classificaci\u00f3 bin\u00e0ria. \u00c9s a dir, ofereixen probabilitats de que un element pertanya a una classe o una altra.</p> <p>D'altra banda, els algorismes de regressi\u00f3 s'utilitzen per predir valors continus, generalment num\u00e8rics. La regressi\u00f3 busca un valor en una s\u00e8rie o rang continu. Per exemple:</p> <ul> <li>un preu</li> <li>una demanda d'energia</li> <li>una estimaci\u00f3 d'antiguitat</li> <li>una estimaci\u00f3 de vendes</li> </ul> <p>Els algorismes de regressi\u00f3 t\u00edpics s\u00f3n:</p> <ul> <li>Regressi\u00f3 lineal</li> <li>Regressi\u00f3 polin\u00f2mica</li> </ul> <p>Els vectors de suport i els arbres de decisions tamb\u00e9 se poden utilitzar, si la variable objectiu \u00e9s continua, com a algorismes de regressi\u00f3. Els SVR (Support Vector Regression) s\u00f3n una variant dels SVM adaptada per a problemes de regressi\u00f3. S\u00f3n \u00fatils si la relaci\u00f3 entre les variables d'entrada i la variable objectiu no \u00e9s lineal.</p> <p>Com hem comentat abans, la regressi\u00f3 log\u00edstica se considera un model m\u00e9s discriminatiu i, per tant, orientat a tasques de classificaci\u00f3.</p> <p>Ara anirem veient un per un, amb una miqueta m\u00e9s de detall, els principals algorismes que hem anomenat.</p>"},{"location":"u04/#regressio-lineal-normal","title":"Regressi\u00f3 lineal normal","text":"<p>Tipus: supervisat / regressi\u00f3</p> <p>Casos d'\u00fas: predicci\u00f3 de un valor y (variable dependent) a partir dels valors d'una variable x (variable independent). Suposem que hi ha una relaci\u00f3 lineal entre ambdues variables. Aix\u00f2 vol dir que un canvi en x provoca un canvi proporcional en y. Si la relaci\u00f3 no \u00e9s lineal, podem utilitzar altres tipus de regressi\u00f3 (per exemple, la regressi\u00f3 polin\u00f2mica que veurem m\u00e9s endavant).</p> <p>Com funciona: ajusta una funci\u00f3 lineal que prediu el valor de y de la manera m\u00e9s exacta possible a partir del valor de x. Sempre hi haur\u00e0 un marge d'error entre les prediccions i els valors reals, el que s'intenta \u00e9s minimitzar eixe marge.</p> <p>Primer se genera una recta tal que minimitze la difer\u00e8ncia entre la pr\u00f2pia recta i els punts que indiquen els valors y coneguts per als valors x coneguts. Normalment s'utilitza l'error quadr\u00e0tic mitj\u00e0 (MSE, Mean Squared Error) per mesurar aquesta difer\u00e8ncia. Se calcula fent la mitjana dels quadrats de les difer\u00e8ncies entre els valors reals i les prediccions del model, i s'ajusta la recta per minimitzar aquest valor.</p> <p>$MSE=\\frac{1}{n}\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^{2}$</p> <p>On n \u00e9s el nombre de mostres, $y_{i}$ \u00e9s el valor real i $\\hat{y}_{i}$ \u00e9s el valor pred\u00eft pel model.</p> <p>La funci\u00f3 lineal t\u00e9 la forma: </p> <p>$y = b_{1}x + b_{0}$</p> <p>on $b_{1}$ \u00e9s la pendent de la l\u00ednia i $b_{0}$ \u00e9s la intersecci\u00f3 amb l'eix y quan el valor de x \u00e9s 0.</p> <p>Nosaltres no necessitarem calcular el MSE, ni la recta, ni la pendent ni el punt d'intersecci\u00f3 manualment, sin\u00f3 que ho far\u00e0 tot l'algorisme per nosaltres a partir de les dades d'entrenament. Ho veurem en els exemples pr\u00e0ctics.</p> <p>Si veiem que el model no produeix els resultats esperats, podem veure si hi ha molts outliers (valors molt despla\u00e7ats de la recta, en este cas) i decidir qu\u00e8 fem en ells (eliminar-los, o fer altre tipus de preprocessament com hem vist abans).</p> <p>Exemples: </p> <ul> <li>predir el preu d'un pis segons els metres quadrats</li> <li>predir la nota d'un estudiant segons les hores d'estudi que dedica al dia</li> </ul> <p></p>"},{"location":"u04/#regressio-lineal-multiple","title":"Regressi\u00f3 lineal m\u00faltiple","text":"<p>Tipus: supervisat / regressi\u00f3</p> <p>Casos d'\u00fas: predicci\u00f3 de un valor y (variable dependent) a partir dels valors d'un conjunt de valors  x_{1}, x_{2}, ..., x_{n} (variables independents). Suposem que hi ha una relaci\u00f3 lineal entre totes les variables independents i la dependent. Aix\u00f2 vol dir que un canvi en qualsevol dels valors de x_{1}, x_{2}, ..., x_{n} provoca un canvi proporcional en y. Si per a algun valor de la llista 'x' no es compleix aquesta relaci\u00f3, podem considerar altres models. O si veiem que no hi cap relaci\u00f3, eliminar la variable independent que no aporta informaci\u00f3. Veurem diferents exemples.</p> <p>De totes formes no \u00e9s convenient utilitzar molts atributs independents, ja que pot provocar problemes de sobreajustament (overfitting) i dificulta la representaci\u00f3 gr\u00e0fica de les correlacions. Si tenim moltes variables independents, podem utilitzar t\u00e8cniques de selecci\u00f3 de caracter\u00edstiques per reduir-ne la quantitat. Tamb\u00e9 veurem exemples d'aix\u00f2.</p> <p>Com funciona: ajusta un pla o hiperpl\u00e0 que minimitza l'error quadr\u00e0tic entre prediccions i valors reals, utilitzant m\u00faltiples variables independents. La funci\u00f3 lineal t\u00e9 la forma:</p> <p>$y = b_{1}x_{1} + b_{2}x_{2} + ... + b_{n}x_{n} + b_{0}$</p> <p>on $b_{1}, b_{2}, ..., b_{n}$ s\u00f3n els coeficients que representen la influ\u00e8ncia de cada variable independent en la variable dependent, i $b_{0}$ \u00e9s la intersecci\u00f3 amb l'eix y quan tots els valors de x s\u00f3n 0.</p> <p>Com en el cas anterior, nosaltres no necessitem calcular res manualment. El que s\u00ed hem de procurar \u00e9s que les dades estiguen ben preparades abans d'entrenar el model perqu\u00e8 si hi ha m\u00e9s d'un valor predictor s'incrementa el risc de situacions que afecten al funcionament correcte del model. Per exemple, si hi ha valors molt despla\u00e7ats (outliers) o si les variables estan en escales molt diferents (per exemple, una variable en metres i una altra en quil\u00f2metres), o tamb\u00e9 si hi ha correlaci\u00f3 entre les variables independents (multicolinealitat), ja que aix\u00f2 pot dificultar la interpretaci\u00f3 dels coeficients i afectar la precisi\u00f3 de les prediccions.</p> <p>La multicolinealitat es pot detectar mitjan\u00e7ant l'an\u00e0lisi de la matriu de correlaci\u00f3 entre les variables independents. Si es detecta una alta correlaci\u00f3 entre dues o m\u00e9s variables, es pot considerar eliminar-ne alguna o utilitzar t\u00e8cniques com l'an\u00e0lisi de components principals (PCA) per reduir la dimensionalitat de les dades.</p> <p>Veurem exemples pr\u00e0ctics de tot, de moment nom\u00e9s cal entendre els conceptes.</p> <p>Exemple: predir el preu d'un pis segons metres quadrats i quantitat d'habitacions.</p>"},{"location":"u04/#regressio-polinomica","title":"Regressi\u00f3 polin\u00f2mica","text":"<p>Tipus: supervisat / regressi\u00f3</p> <p>Casos d'\u00fas: predicci\u00f3 de valors continus amb relacions no lineals. Quan representem gr\u00e0ficament la relaci\u00f3 entre les variables independents i la dependent, i no es veu una l\u00ednia recta sin\u00f3 una corba, podem provar amb la regressi\u00f3 polin\u00f2mica per ajustar millor el model a les dades.</p> <p>Tamb\u00e9 podem intentar una regressi\u00f3 polin\u00f2mica si la regressi\u00f3 lineal no d\u00f3na els resultats esperats, o si veiem que hi ha molts outliers despla\u00e7ats de la recta i no volem eliminar-los ni transformar-los.</p> <p>Com funciona: ajusta una corba polin\u00f2mica als punts de dades. En general el polinomi tindr\u00e0 grau 2, per\u00f2 se pot ajustar a graus m\u00e9s alts si cal. La funci\u00f3 polin\u00f2mica t\u00e9 la forma:</p> <p>$y = b_{n}x^{n} + b_{n-1}x^{n-1} + ... + b_{2}x^{2} + b_{1}x + b_{0}$</p> <p>on n \u00e9s el grau del polinomi i $b_{n}, b_{n-1}, ..., b_{1}$ s\u00f3n els coeficients que representen la influ\u00e8ncia de cada terme polin\u00f2mic en la variable dependent, i $b_{0}$ \u00e9s la intersecci\u00f3 amb l'eix y quan el valor de x \u00e9s 0.</p> <p>Exemple: predir l'evoluci\u00f3 de la temperatura al llarg del dia.</p> <p></p>"},{"location":"u04/#regressio-logistica-binaria","title":"Regressi\u00f3 log\u00edstica bin\u00e0ria","text":"<p>Tipus: supervisat / classificaci\u00f3</p> <p>Casos d'\u00fas: decisions bin\u00e0ries, classificaci\u00f3. Quan la variable que volem predir \u00e9s categ\u00f2rica (per exemple, \"s\u00ed\" o \"no\", \"malaltia\" o \"no malaltia\"). Si hi ha m\u00e9s de dues categories, s'ha d'utilitzar la regressi\u00f3 log\u00edstica multinomial.</p> <p>Com funciona: estima probabilitats per a dues classes amb la funci\u00f3 sigmoide (una corba). El que fa es predir la probabilitat de que una mostra pertanya a una classe o a l'altra. Si la probabilitat \u00e9s major que un cert llindar (normalment 0.5), s'assigna a una classe; si \u00e9s menor, a l'altra.</p> <p>S'utilitzen dues f\u00f3rmules:</p> <ul> <li>una funci\u00f3 l\u00edneal de la inst\u00e0ncia de entrada $x$: </li> </ul> <p>$$\\theta^T x = \\theta_0 + \\sum_{i=1}^{n} \\theta_i x_i$$ </p> <p>on $\\theta^T = (\\theta_0, \\theta_1, \\dots, \\theta_n)$ \u00e9s el vector de par\u00e0metres (pesos) que el model ha d'aprendre durant l'entrenament.</p> <ul> <li>una funci\u00f3 sigmoide que transforma el resultat de la funci\u00f3 lineal en una probabilitat entre 0 i 1:</li> </ul> <p>$P(C=1|x)$: $$f_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}}$$</p> <p>Com sempre, no us heu de preocupar per les f\u00f3rmules. Ja veurem com utilitzar-ho tot en els exemples pr\u00e0ctics en Python.</p> <p>Exemples: </p> <ul> <li>acceptaci\u00f3 o no d'un cr\u00e8dit segons ingressos de la persona sol\u00b7licitant</li> <li>si un client d'un producte renovar\u00e0 o no la subscripci\u00f3 en funci\u00f3 de l'us que ha fet del servei</li> </ul> <p></p>"},{"location":"u04/#regressio-logistica-multiclase-multinomial-o-softmax","title":"Regressi\u00f3 log\u00edstica multiclase (multinomial o softmax)","text":"<p>Tipus: supervisat / classificaci\u00f3</p> <p>Casos d'\u00fas: Quan la variable que volem predir \u00e9s categ\u00f2rica i poden haver m\u00e9s de dues categories (per exemple, \"baix\", \"mitj\u00e0\", \"alt\" o \"roig\", \"verd\", \"blau\"). </p> <p>Com funciona: estima probabilitats per a dues classes amb la funci\u00f3 sigmoide. Hi ha una f\u00f3rmula (softmax) que permet predir la probabilitat de que una mostra pertanya a cada classe. La classe amb la probabilitat m\u00e9s alta \u00e9s la que s'assigna a la mostra. La f\u00f3rmula \u00e9s:</p> <p>$$f_\\theta^{(i)}(x) = \\frac{e^{-\\theta^{(i)T}x}}{\\sum_{j=1}^{|\\Omega_C|} e^{-\\theta^{(j)T}x}}$$</p> <p>L'entrenament del model \u00e9s obtenir els par\u00e0metres $\\theta$ que maximitzen la probabilitat de les dades d'entrenament. \u00c9s a dir, que el model estime una probabilitat alta per a la classe correcta de cada mostra d'entrenament, i una probabilitat baixa de la mateixa mostra per a les altres classes.</p> <p>Per minimitzar l'error s'utilitza una funci\u00f3 de cost denominada cross entropy que no anem a reproduir ac\u00ed. </p> <p>Si la quantitat de classes \u00e9s igual a 2, aquesta funci\u00f3 de cost \u00e9s equivalent a la funci\u00f3 de cost utilitzada en la regressi\u00f3 log\u00edstica bin\u00e0ria</p> <p>Exemple: sempre que tinguem m\u00e9s de 2 classes de classificaci\u00f3, que siguen excloent entre s\u00ed i que no siga una quantitat molt elevada (per a m\u00e9s de 10 o 15 classes ens haur\u00edem de plantejar altres enfocaments com les xarxes neuronals).</p>"},{"location":"u04/#arbres-de-decisio","title":"Arbres de decisi\u00f3","text":"<p>Tipus: supervisat / classificaci\u00f3 i (en alguns casos) regressi\u00f3.</p> <p>Com funciona: utilitza un esquema tipus arbre, dividint les dades en branques segons preguntes sobre atributs, fins a obtenir les fulles que s\u00f3n les decisions finals. \u00c9s a dir, si recordem l'estructura d'un arbre amb un node arrel, branques, nodes interns i fulles, l'equival\u00e8ncia seria:</p> <ul> <li>Node arrel: atribut que millor separa o testeja les dades d'entrada. Genera la primera branca.</li> <li>Nodes interns: atributs utilitzats per particionar o testar les dades en els diferents nivells de l'arbre.</li> <li>Branques: possibles respostes a les preguntes o casos de prova de cada node (excepte les fulles).</li> <li>Fulles: decisions finals. Cada fulla t\u00e9 associada una etiqueta que ser\u00e0 el valor assignat per a l'atribut objectiu (classe).</li> </ul> <p>Al final es tracta d'anar fent preguntes sobre la inst\u00e0ncia que volem classificar i anar baixant nivells fins que arribem a una fulla que ens donar\u00e0 la classificaci\u00f3.</p> <p>Internament, la construcci\u00f3 de l'arbre es fa de forma recursiva en un disseny top-down. En cada node se tria l'atribut que millor divideix el conjunt d'observacions, amb l'objectiu que cada branca (subconjunt) siga el m\u00e9s homog\u00e8nia possible i que les branques estiguen m\u00e9s o menys equilibrades. Per seleccionar l'atribut que millor separa les dades, s'utilitzen mesures com el guany d'informaci\u00f3 (basada en l'entropia) o l'\u00edndex Gini.</p> <p>Casos d'\u00fas: classificaci\u00f3 i regressi\u00f3 amb decisions interpretables.</p> <ul> <li>Classificaci\u00f3: si l'atribut objectiu \u00e9s categ\u00f2ric (tant fa que siga binari com multiclasse).</li> <li>Regressi\u00f3: si l'atribut objectiu \u00e9s num\u00e8ric o continu. L'algorisme CART (Classification and Regression Trees) \u00e9s una variant que permet fer arbres de decisi\u00f3 per a problemes de regressi\u00f3.</li> </ul> <p>De vegades si no tenim clar quin algorisme aplicar, podem provar amb un arbre de decisi\u00f3, ja que \u00e9s f\u00e0cil d'entendre i interpretar, i a m\u00e9s no necessita tant de preprocessament de les dades com altres algorismes. Tamb\u00e9 \u00e9s \u00fatil quan s'han de prendre decisions basades en m\u00faltiples criteris / atributs.</p> <p>Exemple: a partir d'una s\u00e8rie de s\u00edmptomes i resultats de proves m\u00e8diques, predir si un pacient t\u00e9 una malaltia concreta.</p> <p></p>"},{"location":"u04/#random-forest","title":"Random Forest","text":"<p>Tipus: supervisat / classificaci\u00f3 i (en alguns casos) regressi\u00f3.</p> <p>Com funciona: se basa en la combinaci\u00f3 de diferentes \u00e0rbres de decisi\u00f3 per millorar la precisi\u00f3 i evitar l'overfitting. El que fa \u00e9s entrenar m\u00faltiples arbres de decisi\u00f3 amb diferents subconjunts de dades i diferents subconjunts d'atributs. Despr\u00e9s, per a una nova mostra, cada arbre fa una predicci\u00f3 i la classe final es determina per votaci\u00f3 majorit\u00e0ria (en classificaci\u00f3) o per mitjana (en regressi\u00f3).</p> <p>Hi ha dues t\u00e8cniques principals que utilitzen els Random Forest per crear diversitat entre els arbres:</p> <ol> <li>Bagging (Bootstrap Aggregating): es creen m\u00faltiples subconjunts de dades d'entrenament mitjan\u00e7ant mostreig amb reempla\u00e7ament. Cada subconjunt de dades t\u00e9 la mateixa grand\u00e0ria que l'original, per\u00f2 al haver reempla\u00e7ament poden haver inst\u00e0ncies repetides. Aix\u00f2 significa que cada arbre s'entrena amb un conjunt lleugerament diferent de dades, la qual cosa ajuda a reduir la vari\u00e0ncia del model i l'overfitting.</li> </ol> <p>Com ja hem comentat en altres ocasions, l'overfitting \u00e9s un problema que es produeix quan un model s'ajusta massa b\u00e9 a les dades d'entrenament, fins al punt que captura el soroll i les anomalies en lloc de la tend\u00e8ncia general. Aix\u00f2 fa que el model funcione molt b\u00e9 amb les dades d'entrenament per\u00f2 que tinga un rendiment pobre amb noves dades (conjunt de prova).</p> <p>La t\u00e8cnica de Subspace sampling (mostreig de dades amb un subconjunt d'atributs diferents per cada arbre) tamb\u00e9 \u00e9s utiltizada sovint per garantir que els diferents arbres siguen diferents i aix\u00ed evitar l'influ\u00e8ncia excesiva d'alguns atributs.</p> <p>A continuaci\u00f3 es mostra una taula comparativa entre un Random Forest i un Arbre de decisi\u00f3 individual:</p> Aspecte Random Forest Arbre de Decisi\u00f3 Individual (DecisionTreeClassifier) Concepte M\u00e8tode de Ensemble (Bagging) Model individual Entrenament Entrenat en mostres bootstrapped (amb reempla\u00e7ament) Entrenat amb el dataset complet o partici\u00f3 simple Selecci\u00f3 d'Atributs Utilitza un subconjunt aleatori d'atributs (max_features per defecte \u00e9s 'sqrt') en cada divisi\u00f3. Per defecte, considera tots els atributs (max_features \u00e9s None). Risc de Sobreajust Baix (mitigat per l'agregaci\u00f3 de m\u00faltiples resultats). Alt (s\u00f3n especialment proclius al sobreaprenentatge o overfitting). <ol> <li>Boosting (selecci\u00f3 aleat\u00f2ria d'atributs): en cada node de cada arbre, en lloc de considerar tots els atributs per triar el millor per dividir les dades, nom\u00e9s es considera un subconjunt aleatori d'atributs. Aix\u00f2 ajuda a crear arbres m\u00e9s diversos i a reduir la correlaci\u00f3 entre ells. A m\u00e9s, mentre en el bagging podem executar tots els arbres a la vegada perqu\u00e8 s\u00f3n independents, en el boosting l'execuci\u00f3 \u00e9s seq\u00fcencial, de forma que el segon arbre se centra sobretot en les dades que l'arbre anterior no ha classificat correctament. Aix\u00ed se va depurant el proc\u00e9s fins al final.</li> </ol> <p>Una altra difer\u00e8ncia entre el boosting i el bagging \u00e9s que en el boosting la classificaci\u00f3 final es basa en un sistema de vots ponderat, de forma que cada arbre no t\u00e9 el mateix pes en la decisi\u00f3 final.</p> <p>Casos d'\u00fas: classificaci\u00f3 i regressi\u00f3 amb alta dimensionalitat (molts atributs, com que cada arbre pot no utilitzar-los tots i per tant la dimensionalitat alta no \u00e9s un problema tan greu), en detecci\u00f3 d'anomalies o en problemes m\u00e9s complexos.</p> <p>Exemple: predir la probabilitat d'una malaltia a partir d'un historial m\u00e8dic. Un altre exemple: predir si un client renovar\u00e0 la subscripci\u00f3 a un servei de streaming basant-se en el seu comportament d'\u00fas.</p> <p>A continuaci\u00f3 es mostra una taula comparativa entre les t\u00e8cniques de Bagging i Boosting:</p> Aspecte Bagging (p. ej., Random Forest) Boosting (p. ej., AdaBoost) Flux d'Entrenament En paral\u00b7lel (independent). En seq\u00fc\u00e8ncia (incremental i dependent). Objectiu Principal Reduir la vari\u00e0ncia (mitigar el sobreajust o overfitting). Reduir els biaixos (incrementar la complexitat del model per evitar el underfitting). Mostreig de Dades Uniforme amb reempla\u00e7ament (bootstrap). Ponderat (les inst\u00e0ncies mal classificades pels models previs reben major pes/probabilitat de ser escollides pel seg\u00fcent model). Classificadors Base Sovint s\u00f3n models complexos/forts (com arbres de decisi\u00f3 completament desenvolupats o amb poca restricci\u00f3). Sovint s\u00f3n models senzills/d\u00e8bils (com els stumps, arbres de decisi\u00f3 de profunditat m\u00e0xima 1). Decisi\u00f3 Final Vot per majoria simple o mitjana (en el cas de Random Forest). Vot ponderat (cada classificador t\u00e9 un pes en la decisi\u00f3 final). Depend\u00e8ncia Els classificadors individuals s\u00f3n independents entre si. Els classificadors individuals s\u00f3n dependents entre si. <p></p>"},{"location":"u04/#k-nearest-neighbors-knn","title":"K-Nearest Neighbors (KNN)","text":"<p>Tipus: supervisat / classificaci\u00f3 (en alguns casos regressi\u00f3)</p> <p>Com funciona: classifica una mostra segons la majoria de les classes dels K ve\u00efns m\u00e9s propers. Donat un conjunt de dades d'entrenament, per a cada mostra a predir KNN troba les mostres d'entrenament m\u00e9s properes a ella i assigna l'etiqueta de classificaci\u00f3 m\u00e9s comuna entre elles. KNN es basa en la idea de que elements o dades similars estan a prop uns dels altres en un espai de n dimensions, on n \u00e9s la quantitat d'atributs predictors.</p> <p>Per exemple: en la imatge seg\u00fcent, KNN amb K=3 assignaria l'etiqueta de classificaci\u00f3 \"triangle vermell\" al punt de prova verd perqu\u00e8 de les 3 mostres m\u00e9s properes a ell, la majoria, dues, s\u00f3n triangles vermells. Per\u00f2 si K=5, KNN assignaria l'etiqueta de classificaci\u00f3 \"quadradet blau\" al punt de prova.</p> <p></p> <p>KNN tamb\u00e9 pot utilitzar-se per a problemes de regressi\u00f3, assignant la mitjana (ponderada o no) dels valors dels punts d'entrenament m\u00e9s propers al punt de prova.</p> <p>Casos d'\u00fas: hem de tenir en compte que l'algorisme KNN no apr\u00e8n ni s'entrena, simplement utilitza el conjunt de dades com a base de coneixement per a les noves dades. Per tant, cada vegada que ha de fer una predicci\u00f3 utilitza tot el dataset. Aix\u00f2 requereix de mem\u00f2ria i recursos de processament importants. Per tant, KNN \u00e9s lent i no recomanable per a conjunts grans de dades.</p> <p>Com que KNN es basa en la dist\u00e0ncia entre les mostres, \u00e9s molt sensible a l'escalat i a les unitats emprades dels atributs predictors. \u00c9s important normalitzar o estandarditzar les dades abans d'utilitzar KNN.</p> <p>Exemple: classificar plantes segons mides de les fulles.</p>"},{"location":"u04/#support-vector-machines-svm","title":"Support Vector Machines (SVM)","text":"<p>Tipus: supervisat / classificaci\u00f3 (principalment) o regressi\u00f3 (SVR)</p> <p>Com funciona: cada inst\u00e0ncia de la mostra d'entrenament se dibuixa com un punt en un espai $n$-dimensional, on $n$ \u00e9s la quantitat d'atributs predictors. L'objectiu \u00e9s cercar la frontera (un hiperpl\u00e0) que maximitza la separaci\u00f3 entre classes. Aix\u00f2 s'aconsegueix calculant la recta que separa els grups de forma que estiga equidistant dels dos punts m\u00e9s propers de cada classe. A estos punts de dades que defineixen la dist\u00e0ncia del marge se'ls anomena vectors suport.</p> <p>Si les dades no s\u00f3n linealment separables, i no \u00e9s possible trobar un hiperpl\u00e0 que separe les dues classes, s'utilitza el truc del nucli (kernel trick). El que fa este procediment \u00e9s transformar les dades a un espai de major dimensi\u00f3 on s\u00ed que es puga trobar un hiperpl\u00e0 que les separe linealment. Aix\u00f2 es fa mitjan\u00e7ant funcions de nucli com el nucli lineal, polin\u00f2mic o RBF (Radial Basis Function).</p> <p>No us preocupeu per les f\u00f3rmules ni els c\u00e0lculs, ja que Python ens aporta llibreries i funcions per fer-ho tot autom\u00e0ticament. El que hem de intentar saber \u00e9s quines funcions s\u00f3n millors en cada cas.</p> <p>Casos d'\u00fas: classificaci\u00f3 bin\u00e0ria amb marges clars, tamb\u00e9 per detecci\u00f3 d'anomalies. En situacions amb prou soroll en les dades, dades mal etiquetades o amb solapament entre classes, les SVM poden no funcionar b\u00e9. En eixe cas s'utilitzen hiperpar\u00e0metres de regularitzaci\u00f3 que permeten ajustar l'overfitting i la proporci\u00f3 d'errors assumibles. </p> <p>Els hiperpar\u00e0metres s\u00f3n valors que ens ajuden a optimitzar les nostres funcions a l'hora d'entrenar models. Per exemple, en </p> <p><code>clf = svm.SVC(kernel='linear', C=1);</code></p> <p>Tant kernel com C s\u00f3n hiperpar\u00e0metres. Pel que fa a la regularitzaci\u00f3, l'hiperpar\u00e0metre m\u00e9s com\u00fa \u00e9s C. Un valor alt de C intenta classificar totes les mostres correctament, el que pot portar a un sobreajustament. Un valor baix de C permet m\u00e9s errors en l'entrenament, el que pot millorar la generalitzaci\u00f3 del model per\u00f2 tamb\u00e9 por portar a un subajustament. L'objectiu \u00e9s trobar un equilibri adequat entre els dos extrems.</p> <p>Tamb\u00e9 \u00e9s important tenir en compte que les SVM poden ser lentes en conjunts de dades molt grans, ja que la complexitat computacional de manera exponencial augmenta amb la quantitat de mostres i atributs.</p> <p>Exemple: classificar emails com a spam/no spam.</p> <p>Si les classes s\u00f3n linealment separables de manera senzilla, un algorisme m\u00e9s senzill com la regressi\u00f3 log\u00edstica pot donar resultats similars amb menys complexitat computacional. SVM seria m\u00e9s adequat quan les classes no s\u00f3n linealment separables i es necessita un marge clar de separaci\u00f3 o fins i tot aplicar el truc del nucli per transformar les dades.</p>"},{"location":"u04/#naive-bayes","title":"Naive Bayes","text":"<p>Tipus: supervisat / classificaci\u00f3</p> <p>Com funciona: aplica el teorema de Bayes amb la suposici\u00f3 d'independ\u00e8ncia entre atributs. Com eixa suposici\u00f3 moltes vegades \u00e9s falsa (si hi ha certe correlaci\u00f3 entre atributs, ja no s\u00f3n independents), per aix\u00f2 s'anomena \"naive\" (ingenu). </p> <p>El teorema de Bayes permet calcular la probabilitat d'una classe donada una inst\u00e0ncia d'entrada, basant-se en les probabilitats pr\u00e8vies i les evid\u00e8ncies observades.</p> <p>Un avantatge de Naive Bayes \u00e9s que \u00e9s eficient tant si treballem amb atributs predictors continus com categ\u00f2rics. Ara b\u00e9, si els atributs categ\u00f2rics no s\u00f3n dicot\u00f2mics (m\u00e9s de dos valors possibles), caldr\u00e0 transformar-los en variables fict\u00edcies num\u00e8riques (one-hot encoding) abans d'utilitzar l'algorisme.</p> <p>Tamb\u00e9 t\u00e9 desavantatges: \u00e9s sensible a atributs predictors irrelevants o redundants, i no gestiona b\u00e9 atributs correlacionats. A m\u00e9s, si en les dades d'entrenament hi ha una combinaci\u00f3 d'atributs que no apareix, la probabilitat ser\u00e0 zero i aix\u00f2 pot afectar negativament les prediccions. Per evitar-ho, s'utilitza el Laplace smoothing, que afegeix una petita constant a les freq\u00fc\u00e8ncies per evitar probabilitats zero.</p> <p>Casos d'\u00fas: situacions de classificaci\u00f3 amb incertesa, variabilitat o falta de dades. Tamb\u00e9 t\u00e9 aplicaci\u00f3 en el camp del processament del llenguatge natural (NLP), en an\u00e0lisi de sentiments i en sistemes de recomanaci\u00f3. \u00c9s m\u00e9s eficient que altres algorismes si tenim poques dades d'entrenament per\u00f2 s\u00ed que hi ha independ\u00e8ncia entre els atributs.</p> <p>De vegades tamb\u00e9 s'utilitza com un primer classificador, per despr\u00e9s comparar els resultats amb altres algorismes m\u00e9s complexos. De fet, si funciona b\u00e9, com que \u00e9s senzill i r\u00e0pid pot ser la primera i \u00fanica opci\u00f3.</p> <p>Exemple: classificar dades en funci\u00f3 d'informaci\u00f3 que arriba continuament des de sensors, classificar documents o correus electr\u00f2nics, etc. </p>"}]}